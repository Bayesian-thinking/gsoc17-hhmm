# Input Output Hidden Markov Models

The Input/Output Hidden Markov Model (IOHMM) is an alternative architecture proposed by @bengio1995input to learn to map input sequences to output sequences.

IOHMM can be seen as a recurrent version of a mixture of experts (cite?).

HMM is unsupervised. HMM learns the output sequence distribution but not the output sequence itself.

Although effective for learning short  term  memories, many of these alternatives suffer from practical difficulties when the input/output sequences span long points.

general sequence processing tasks, such as production, classification, or prediction, can be dealt with

## Model specification
As with HMM, IOHMM involves two interconnected models. 
\[
z_{t} = f(z_{t-1}, \mat{u}_{t}) \\
\mat{y}_{t} = g(z_{t  }, \mat{u}_{t})
\]

The first line corresponds to the state model, which consists of a discrete-time, discrete-state Markov chain with hidden states $z_t \in \{1, \dots, K\}$ that transition according to $f(z_t | z_{t-1}, \mat{u}_{t})$. Additionally, the observation model is governed by $g(z_{t  }, \mat{u}_{t})$, where $\mat{u}_{t} \in \RR^m$ is the input vector and $\mat{x}_t \in \RR^r$ is the vector of observations, emissions or output. The corresponding joint distribution is

To make this model probabilistic, state variables are assumed to follow a multinomial distribution. The belief states now becomes

\begin{align*}
\alpha_t(j) 
  & \triangleq  p(z_t = j | \mat{u}_{1:t}). \\
\end{align*}

The transition probabilities $\Psi(i, j) = p(z_t = j | z_{t-1} = i)$ govern the state dynamics. The output $\mat{eta}_t = \ev{\mat{x}_t | z_t, \mat{u}_t}$ can be interpreted as the expected location parameter for the probability distribution of the emission $\mat{x}$_{t}, conditional on the input $\mat{u}_t$ and the hidden state $\mat{z}_t$. The actual form of the emission density $f_{\mat{x}}(\mat{x}_t, \mat{eta}_t)$ can be discrete or continuous. In case of sequence classification or symbolic mutually exclusive emissions, a multinomial distribution can be achieved by application the softmax function to the outputs. If the chosen density is Gaussian, then the target is a linear combination of the output.

Following a probabilistic logic, the inputs and state distributions at a given point are used to estimate the state distribution and the output distribution for the next step.

  