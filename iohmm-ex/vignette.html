<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Luis Damiano, Brian Peterson, Michael Weylandt" />

<meta name="date" content="2017-06-13" />

<title>Input-Output Hidden Markov Model</title>

\(
% Math operators
\newcommand{\argmax}{\arg\!\max}
\newcommand\ev[1]{E\left\langle#1\right\rangle}
\newcommand\vv[1]{V\left\langle#1\right\rangle}

% Math commands
\newcommand{\mat}[1]{\mathbf{#1}}

% Math symbols
\renewcommand{\RR}{\mathbb{R}}
\)


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Input-Output Hidden Markov Model</h1>
<h4 class="author"><em>Luis Damiano, Brian Peterson, Michael Weylandt</em></h4>
<h4 class="date"><em>2017-06-13</em></h4>



<p>This work aims at replicating the Input-Output Hidden Markov Model (IOHMM) originally proposed by <span class="citation">Hassan and Nath (2005)</span> to forecast stock prices. The main goal is to produce public programming code in <a href="http://mc-stan.org/">Stan</a> <span class="citation">(Carpenter et al. 2016)</span> for a fully Bayesian estimation of the model parameters and inference on hidden quantities, namely filtered state belief, smoothed state belief, jointly most probable state path and fitted output. The model is introduced only briefly, a more detailed mathematical treatment can be found in our <a href="../litreview/main.pdf">literature review</a>.</p>
<div id="acknowledgements" class="section level3">
<h3>Acknowledgements</h3>
<p>The authors acknowledge Google for financial support via the Google Summer of Code 2017.</p>
<hr />
</div>
<div id="the-input-output-hidden-markov-model" class="section level1">
<h1>The Input-Output Hidden Markov Model</h1>
<p>The IOHMM is an architecture proposed by <span class="citation">Bengio and Frasconi (1995)</span> to map input sequences, sometimes called the control signal, to output sequences. It is a probabilistic framework that can deal with general sequence processing tasks such as production, classification, or prediction. It differs from HMM, which is part of the unsupervised learning paradigm, since it is capable of learning the output sequence itself instead of learning only the output sequence distribution.</p>
<div id="definitions" class="section level2">
<h2>Definitions</h2>
<p>As with HMM, IOHMM involves two interconnected models,</p>
<span class="math display">\[\begin{align*}
z_{t} &amp;= f(z_{t-1}, \mat{u}_{t}) \\
\mat{x}_{t} &amp;= g(z_{t  }, \mat{u}_{t}).
\end{align*}\]</span>
<p>The first line corresponds to the state model, which consists of discrete-time, discrete-state hidden states <span class="math inline">\(z_t \in \{1, \dots, K\}\)</span> whose transition depends on the previous hidden state <span class="math inline">\(z_{t-1}\)</span> and the input vector <span class="math inline">\(\mat{u}_{t} \in \RR^M\)</span>. Additionally, the observation model is governed by <span class="math inline">\(g(z_{t}, \mat{u}_{t})\)</span>, where <span class="math inline">\(\mat{x}_t \in \RR^R\)</span> is the vector of observations, emissions or output. The corresponding joint distribution is</p>
<p><span class="math display">\[
p(\mat{z}_{1:T}, \mat{x}_{1:T} | \mat{u}_{t}).
\]</span></p>
<p>In the proposed parametrization wtih continuous inputs and outputs, the state model involves a multinomial regression whose parameters depend on the previous state taking the value <span class="math inline">\(i\)</span>,</p>
<p><span class="math display">\[
p(z_t | \mat{x}_{t}, \mat{u}_{t}, z_{t-1} = i) = \text{softmax}^{-1}(\mat{w}_i \mat{u}_{t}),
\]</span></p>
<p>and the observation model is built upon the Gaussian density with parameters depending on the current state taking the value <span class="math inline">\(j\)</span>,</p>
<p><span class="math display">\[
p(\mat{x}_t | \mat{u}_{t}, z_{t} = j) = \mathcal{N}(\mat{x}_t | \mat{b}_j \mat{u}_t, \mat{\Sigma}_j).
\]</span></p>
<p>IOHMM adapts the logics of HMM to allow for input and output vectors, retaining its fully probabilistic quality. Hidden states are assumed to follow a multinomial distribution that depends on the input sequence. The transition probabilities <span class="math inline">\(\Psi_t(i, j) = p(z_t = j | z_{t-1} = i, \mat{u}_{t})\)</span>, which govern the state dynamics, are driven by the control signal as well.</p>
<p>As for the output sequence, the local evidence at time <span class="math inline">\(t\)</span> now becomes <span class="math inline">\(\psi_t(j) = p(\mat{x}_t | z_t = j, \mat{\eta}_t)\)</span>, where <span class="math inline">\(\mat{\eta}_t = \ev{\mat{x}_t | z_t, \mat{u}_t}\)</span> can be interpreted as the expected location parameter for the probability distribution of the emission <span class="math inline">\(\mat{x}_{t}\)</span> conditional on the input vector <span class="math inline">\(\mat{u}_t\)</span> and the hidden state <span class="math inline">\(z_t\)</span>.</p>
</div>
<div id="inference" class="section level2">
<h2>Inference</h2>
<p>There are several quantities of interest to be inferred from different algorithms. In this section, the discussion assumes that model parameters <span class="math inline">\(\mat{\theta}\)</span> are known.</p>
<div id="filtering" class="section level3">
<h3>Filtering</h3>
<p>A filter infers the belief state at a given step based on all the information available up to that point,</p>
<span class="math display">\[\begin{align*}
\alpha_t(j)
  &amp; \triangleq p(z_t = j | \mat{x}_{1:t}, \mat{u}_{1:t}).
\end{align*}\]</span>
<p>It achieves better noise reduction than simply estimating the hidden state based on the current estimate <span class="math inline">\(p(z_t | \mat{x}_{t})\)</span>. The filtering process can be run online, or recursively, as new data streams in. Filtered maginals can be computed recursively by means of the forward algorithm <span class="citation">(Baum and Eagon 1967)</span>.</p>
</div>
<div id="smoothing" class="section level3">
<h3>Smoothing</h3>
<p>A smoother infers the belief state at a given state based on all the observations or evidence,</p>
<p><span class="math display">\[
\begin{align*}
\gamma_t(j)
  &amp; \triangleq p(z_t = j | \mat{x}_{1:T}, \mat{u}_{1:T}) \\
  &amp; \propto \alpha_t(j) \beta_t(j),
\end{align*}
\]</span></p>
<p>where</p>
<span class="math display">\[\begin{align*}
\beta_{t-1}(i)
  &amp; \triangleq p(\mat{x}_{t:T} | z_{t-1} = i, \mat{u}_{t:T}).
\end{align*}\]</span>
<p>Although noise and uncertainty are significantly reduced as a result of conditioning on past and future data, the smoothing process can only be run offline. Inference can be done by means of the forwards-backwards algorithm, also know as the Baum-Welch algorithm <span class="citation">(Baum and Eagon 1967, <span class="citation">Baum et al. (1970)</span>)</span>.</p>
</div>
<div id="most-likely-hidden-path" class="section level3">
<h3>Most likely hidden path</h3>
<p>It is also of interest to compute the most probable state sequence or path,</p>
<p><span class="math display">\[
\mat{z}^* = \argmax_{\mat{z}_{1:T}} p(\mat{z}_{1:T} | \mat{x}_{1:T}).
\]</span></p>
<p>The jointly most probable sequence of states can be inferred by means of maximum a posterior (MAP) estimation or Viterbi decoding.</p>
</div>
</div>
<div id="parameter-estimation" class="section level2">
<h2>Parameter estimation</h2>
<p>The parameters of the models are <span class="math inline">\(\mat{\theta} = (\mat{\pi}_1, \mat{\theta}_h, \mat{\theta}_o)\)</span>, where <span class="math inline">\(\mat{\pi}_1\)</span> is the initial state distribution, <span class="math inline">\(\mat{\theta}_h\)</span> are the parameters of the hidden model and <span class="math inline">\(\mat{\theta}_o\)</span> are the parameters of the state-conditional density function <span class="math inline">\(p(\mat{x}_t | z_t = j, \mat{u}_t)\)</span>. The form of <span class="math inline">\(\mat{\theta}_h\)</span> and <span class="math inline">\(\mat{\theta}_o\)</span> depend on the specification of the model. State transition may be characterized by a logistic or multinomial regression with parameters <span class="math inline">\(\mat{w}_k\)</span> for <span class="math inline">\(k \in \{1, \dots, K\}\)</span>, while emissions may be modelled with with a linear regression with Gaussian error with parameters <span class="math inline">\(\mat{b}_k\)</span> and <span class="math inline">\(\mat{\Sigma}_k\)</span> for <span class="math inline">\(k \in \{1, \dots, K\}\)</span>.</p>
<hr />
</div>
</div>
<div id="learning-by-simulation" class="section level1">
<h1>Learning by simulation</h1>
<p>We first create a simulation routine that generates data complying with the model assumptions and we then write a MCMC sampler in Stan to recover the parameters and other hidden quantities. Next, we feed our model with the real data used in the original work and analyse the results.</p>
<p>We believe that learning by simulation has many benefits, including:</p>
<ul>
<li>The possibility to confirm that the sampler works as intended, i.e. it retrieves the parameters used to generate the data.</li>
<li>The generated data meets all the assumptions and the estimates are free of the effects of data contamination due to unmodeled phenomena, thus simplifying the interpretation of the results.</li>
<li>The user can gain insight into the model functioning by trying different combinations of the parameters, inputs and outputs.</li>
</ul>
<div id="auxiliary-files" class="section level2">
<h2>Auxiliary files</h2>
<div id="math-functions" class="section level3">
<h3>Math functions</h3>
<p>We write an auxiliary R function to compute the softmax transformation of a given vector. The calculations are run in log scale for greater numerical stability, i.e. to avoid any overflow.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">source</span>(<span class="st">'R/math.R'</span>)</code></pre></div>
</div>
<div id="plot-functions" class="section level3">
<h3>Plot functions</h3>
<p>As plots are extensively used, we arrange the code in an auxiliary file.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">source</span>(<span class="st">'R/plots.R'</span>)</code></pre></div>
</div>
<div id="simulation-functions" class="section level3">
<h3>Simulation functions</h3>
<p>We arrange the code to generate simulated data, as explained below, in an auxiliary file.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">source</span>(<span class="st">'R/iohmm-sim.R'</span>)</code></pre></div>
</div>
</div>
<div id="generative-model" class="section level2">
<h2>Generative model</h2>
<p>We first write an R function for our generative model. The arguments are the sequence length <span class="math inline">\(T\)</span>, the number of discrete hidden states <span class="math inline">\(K\)</span>, the input matrix <span class="math inline">\(\mat{u}\)</span>, the initial state distribution vector <span class="math inline">\(\mat{\pi}_1\)</span>, a matrix wit the regressor of the multinomial regression that rules the hidden states dynamics <span class="math inline">\(\mat{w}\)</span>, the name of a function drawing samples from the observation distribution and its parameters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">iohmm_sim &lt;-<span class="st"> </span>function(T, K, u, w, p.init, obs.model, b, s) {
  m &lt;-<span class="st"> </span><span class="kw">ncol</span>(u)

  if (<span class="kw">dim</span>(u)[<span class="dv">1</span>] !=<span class="st"> </span>T)
    <span class="kw">stop</span>(<span class="st">&quot;The input matrix must have T rows.&quot;</span>)

  if (<span class="kw">any</span>(<span class="kw">dim</span>(w) !=<span class="st"> </span><span class="kw">c</span>(K, m)))
    <span class="kw">stop</span>(<span class="st">&quot;The transition weight matrix must be of size Kxm, where m is the size of the input vector.&quot;</span>)

  if (<span class="kw">any</span>(<span class="kw">dim</span>(b) !=<span class="st"> </span><span class="kw">c</span>(K, m)))
    <span class="kw">stop</span>(<span class="st">&quot;The regressors matrix must be of size Kxm, where m is the size of the input vector.&quot;</span>)

  if (<span class="kw">length</span>(p.init) !=<span class="st"> </span>K)
    <span class="kw">stop</span>(<span class="st">&quot;The vector p.init must have length K.&quot;</span>)

  p.mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow =</span> T, <span class="dt">ncol =</span> K)
  p.mat[<span class="dv">1</span>, ] &lt;-<span class="st"> </span>p.init

  z &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;numeric&quot;</span>, T)
  z[<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dt">x =</span> <span class="dv">1</span>:K, <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>, <span class="dt">prob =</span> p.init)
  for (t in <span class="dv">2</span>:T) {
    p.mat[t, ] &lt;-<span class="st"> </span><span class="kw">softmax</span>(<span class="kw">sapply</span>(<span class="dv">1</span>:K, function(j) {u[t, ] %*%<span class="st"> </span>w[j, ]}))
    z[t] &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dt">x =</span> <span class="dv">1</span>:K, <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>, <span class="dt">prob =</span> p.mat[t, ])
  }

  x &lt;-<span class="st"> </span><span class="kw">do.call</span>(obs.model, <span class="kw">list</span>(u, z, b, s))

  <span class="kw">list</span>(
    <span class="dt">u =</span> u,
    <span class="dt">z =</span> z,
    <span class="dt">x =</span> x,
    <span class="dt">p.mat =</span> p.mat
  )
}</code></pre></div>
<p>The initial hidden state is drawn from a multinomial distribution with one trial and event probabilities given by the initial state probability vector <span class="math inline">\(\mat{\pi}_1\)</span>. The transition probabilities for each of the following steps <span class="math inline">\(t\)</span> are computed from a multinomial linear regression with vector parameters <span class="math inline">\(\mat{w}_k\)</span>, one set per possible hidden state <span class="math inline">\(k = 1, \dots, K\)</span>, and covariates <span class="math inline">\(\mat{u}_t\)</span>. The hidden states are subsequently sampled based on the transition probabilities.</p>
<p>The observation for each step generates from a linear regressions with regressors <span class="math inline">\(\mat{b}_k\)</span> and error variance <span class="math inline">\(\mat{\Sigma}_k\)</span>, one set per possible hidden state.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obs.model &lt;-<span class="st"> </span>function(u, z, b, s) {
  T.length &lt;-<span class="st"> </span><span class="kw">nrow</span>(u)

  x &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;numeric&quot;</span>, T.length)
  for (t in <span class="dv">1</span>:T.length) {
    x[t] &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>, u[t, ] %*%<span class="st"> </span>b[z[t], ], s[z[t]])
  }
  <span class="kw">return</span>(x)
}</code></pre></div>
<p>We set up our simulated experiments with arbitrary values for all the involved parameters. Additionally, we define the settings for the Markov Chain Monte Carlo sampler.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set up ------------------------------------------------------------------</span>

<span class="co"># Data</span>
T.length =<span class="st"> </span><span class="dv">300</span>
K =<span class="st"> </span><span class="dv">3</span>
M =<span class="st"> </span><span class="dv">4</span>
R =<span class="st"> </span><span class="dv">1</span>
u.intercept =<span class="st"> </span><span class="ot">FALSE</span>
w =<span class="st"> </span><span class="kw">matrix</span>(
  <span class="kw">c</span>(<span class="fl">1.2</span>, <span class="fl">0.5</span>, <span class="fl">0.3</span>, <span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">1.2</span>, <span class="fl">0.3</span>, <span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">0.1</span>, <span class="fl">1.2</span>, <span class="fl">0.1</span>),
  <span class="dt">nrow =</span> K, <span class="dt">ncol =</span> M, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)
b =<span class="st"> </span><span class="kw">matrix</span>(
  <span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="fl">0.01</span>, -<span class="fl">0.5</span>, <span class="fl">0.01</span>, -<span class="dv">1</span>, -<span class="dv">5</span>, <span class="fl">0.2</span>),
  <span class="dt">nrow =</span> K, <span class="dt">ncol =</span> M, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)
s =<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.25</span>, <span class="dv">1</span>, <span class="fl">2.5</span>)
p1 =<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.45</span>, <span class="fl">0.10</span>, <span class="fl">0.45</span>)

<span class="co"># Markov Chain Monte Carlo</span>
n.iter =<span class="st"> </span><span class="dv">500</span>
n.warmup =<span class="st"> </span><span class="dv">250</span>
n.chains =<span class="st"> </span><span class="dv">1</span>
n.cores =<span class="st"> </span><span class="dv">1</span>
n.thin =<span class="st"> </span><span class="dv">1</span>
n.seed =<span class="st"> </span><span class="dv">9000</span></code></pre></div>
<p>It is worth noting that we decide to rely on only one chain to avoid between-chain label switching of regression parameters.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> We refer the reader to <span class="citation">Betancourt (2017)</span> for an in-depth treatment of the diagnostics, causes and possible solutions for label switching in Bayesian Mixture Models.</p>
<p>We create random inputs from a standard Gaussian distribution and generate the dataset accordingly.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Data simulation ---------------------------------------------------------</span>
<span class="kw">set.seed</span>(n.seed)
u &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(T.length*M, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">nrow =</span> T.length, <span class="dt">ncol =</span> M)
if (u.intercept)
  u[, <span class="dv">1</span>] =<span class="st"> </span><span class="dv">1</span>

dataset &lt;-<span class="st"> </span><span class="kw">iohmm_sim</span>(T.length, K, u, w, p1, obs.model, b, s)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot_inputoutput</span>(<span class="dt">x =</span> dataset$x, <span class="dt">u =</span> dataset$u, <span class="dt">z =</span> dataset$z)</code></pre></div>
<p><img src="data:image/png;base64,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" width="\textwidth" /></p>
<p>We observe how the chosen values for the parameters affect the generated data. For example, the relationship between the third input <span class="math inline">\(\mat{u}_3\)</span> and the output <span class="math inline">\(\mat{x}\)</span> is positive, indifferent and negative for the hidden states 1 to 3, the true slopes being 7, 0.01 and -5 respectively.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot_inputprob</span>(<span class="dt">u =</span> dataset$u, <span class="dt">p.mat =</span> dataset$p.mat, <span class="dt">z =</span> dataset$z)</code></pre></div>
<p><img src="data:image/png;base64,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" width="\textwidth" /></p>
<p>We then analyse the relationship between the input and the state probabilities, which are usually hidden in applications with real data. We observe the strongest relationships between the pairs <span class="math inline">\(\mat{u}_1, p(z_t = 1)\)</span>, <span class="math inline">\(\mat{u}_2, p(z_t = 2)\)</span> and <span class="math inline">\(\mat{u}_3, p(z_t = 3)\)</span>, which is unsurprising given the values of the true regression parameters: those inputs take the largest weight in each state, namely <span class="math inline">\(w_{11} = 1.2\)</span>, <span class="math inline">\(w_{22} = 1.2}\)</span> and <span class="math inline">\(w_{33} = 1.2\)</span>.</p>
<p>Using a fully Bayesian approach, we now rely on our MCMC sampler to draw samples from the posterior density of model parameters and other hidden quantities.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Model estimation --------------------------------------------------------</span>
<span class="kw">library</span>(rstan)</code></pre></div>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code>## Loading required package: StanHeaders</code></pre>
<pre><code>## rstan (Version 2.14.2, packaged: 2017-03-19 00:42:29 UTC, GitRev: 5fa1e80eb817)</code></pre>
<pre><code>## For execution on a local, multicore CPU with excess RAM we recommend calling
## rstan_options(auto_write = TRUE)
## options(mc.cores = parallel::detectCores())</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(shinystan)</code></pre></div>
<pre><code>## Loading required package: shiny</code></pre>
<pre><code>## 
## This is shinystan version 2.3.0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rstan_options</span>(<span class="dt">auto_write =</span> <span class="ot">TRUE</span>)
<span class="kw">options</span>(<span class="dt">mc.cores =</span> parallel::<span class="kw">detectCores</span>())

stan.model =<span class="st"> 'stan/iohmm.stan'</span>
stan.data =<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">T =</span> T.length,
  <span class="dt">K =</span> K,
  <span class="dt">M =</span> M,
  <span class="dt">u_tm =</span> <span class="kw">as.array</span>(u),
  <span class="dt">x_t =</span> dataset$x
)

stan.fit &lt;-<span class="st"> </span><span class="kw">stan</span>(<span class="dt">file =</span> stan.model,
                 <span class="dt">model_name =</span> stan.model,
                 <span class="dt">data =</span> stan.data, <span class="dt">verbose =</span> T,
                 <span class="dt">iter =</span> n.iter, <span class="dt">warmup =</span> n.warmup,
                 <span class="dt">thin =</span> n.thin, <span class="dt">chains =</span> n.chains,
                 <span class="dt">cores =</span> n.cores, <span class="dt">seed =</span> n.seed)</code></pre></div>
<pre><code>## 
## TRANSLATING MODEL 'stan/iohmm.stan' FROM Stan CODE TO C++ CODE NOW.
## successful in parsing the Stan model 'stan/iohmm.stan'.
## 
## CHECKING DATA AND PREPROCESSING FOR MODEL 'iohmm-ex/stan/iohmm.stan' NOW.
## 
## COMPILING MODEL 'iohmm-ex/stan/iohmm.stan' NOW.
## 
## STARTING SAMPLER FOR MODEL 'iohmm-ex/stan/iohmm.stan' NOW.
## 
## SAMPLING FOR MODEL 'iohmm-ex/stan/iohmm.stan' NOW (CHAIN 1).
## 
## Chain 1, Iteration:   1 / 500 [  0%]  (Warmup)
## Chain 1, Iteration:  50 / 500 [ 10%]  (Warmup)
## Chain 1, Iteration: 100 / 500 [ 20%]  (Warmup)
## Chain 1, Iteration: 150 / 500 [ 30%]  (Warmup)
## Chain 1, Iteration: 200 / 500 [ 40%]  (Warmup)
## Chain 1, Iteration: 250 / 500 [ 50%]  (Warmup)
## Chain 1, Iteration: 251 / 500 [ 50%]  (Sampling)
## Chain 1, Iteration: 300 / 500 [ 60%]  (Sampling)
## Chain 1, Iteration: 350 / 500 [ 70%]  (Sampling)
## Chain 1, Iteration: 400 / 500 [ 80%]  (Sampling)
## Chain 1, Iteration: 450 / 500 [ 90%]  (Sampling)
## Chain 1, Iteration: 500 / 500 [100%]  (Sampling)
##  Elapsed Time: 114.334 seconds (Warm-up)
##                82.559 seconds (Sampling)
##                196.893 seconds (Total)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n.samples =<span class="st"> </span>(n.iter -<span class="st"> </span>n.warmup) *<span class="st"> </span>n.chains</code></pre></div>
<p>We rely on the Rhat statistics and several diagnostic plots provided by shinystan<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> to assess mixing, convergence and the inexistence of divergences. We extract the samples for some quantities of interest, namely the filtered probabilities <span class="math inline">\(\mat{alpha}_t\)</span>, the smoothed probability vector <span class="math inline">\(\mat{\gamma}_t\)</span>, the most probable hidden path <span class="math inline">\(\mat{z}^*\)</span> and the fitted output <span class="math inline">\(\hat{x}\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># MCMC Diagnostics --------------------------------------------------------</span>
<span class="kw">options</span>(<span class="dt">digits =</span> <span class="dv">2</span>)
<span class="kw">summary</span>(stan.fit,
        <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">'p_1k'</span>, <span class="st">'w_km'</span>, <span class="st">'b_km'</span>, <span class="st">'s_k'</span>),
        <span class="dt">probs =</span> <span class="kw">c</span>(<span class="fl">0.50</span>))$summary</code></pre></div>
<pre><code>##             mean se_mean    sd     50% n_eff Rhat
## p_1k[1]    0.263  0.0137 0.216  0.2265   250    1
## p_1k[2]    0.250  0.0126 0.196  0.1954   245    1
## p_1k[3]    0.487  0.0146 0.231  0.4980   250    1
## w_km[1,1]  0.171  0.2617 3.009  0.6202   132    1
## w_km[1,2]  0.201  0.3409 2.878  0.0105    71    1
## w_km[1,3]  0.065  0.2177 2.830  0.0045   169    1
## w_km[1,4]  0.745  0.2756 2.973  0.6329   116    1
## w_km[2,1]  0.301  0.2611 3.016  0.8565   133    1
## w_km[2,2]  0.390  0.3421 2.873  0.2341    70    1
## w_km[2,3] -0.012  0.2167 2.830 -0.1574   171    1
## w_km[2,4]  0.395  0.2737 2.971  0.2001   118    1
## w_km[3,1]  0.117  0.2598 3.002  0.5581   134    1
## w_km[3,2]  0.259  0.3421 2.868  0.0983    70    1
## w_km[3,3] -0.162  0.2154 2.816 -0.2350   171    1
## w_km[3,4]  0.534  0.2720 2.945  0.3449   117    1
## b_km[1,1] -0.101  0.0221 0.341 -0.0981   237    1
## b_km[1,2] -1.067  0.0177 0.281 -1.0678   250    1
## b_km[1,3] -4.884  0.0318 0.329 -4.8936   107    1
## b_km[1,4] -0.083  0.0203 0.320 -0.0782   250    1
## b_km[2,1]  0.845  0.0081 0.128  0.8495   250    1
## b_km[2,2]  5.002  0.0058 0.091  4.9994   250    1
## b_km[2,3]  0.052  0.0072 0.100  0.0634   191    1
## b_km[2,4] -0.261  0.0076 0.111 -0.2712   214    1
## b_km[3,1]  5.049  0.0022 0.035  5.0488   250    1
## b_km[3,2]  6.012  0.0017 0.026  6.0155   250    1
## b_km[3,3]  6.992  0.0015 0.022  6.9899   214    1
## b_km[3,4]  0.456  0.0022 0.034  0.4556   250    1
## s_k[1]     2.741  0.0133 0.211  2.7324   250    1
## s_k[2]     1.025  0.0061 0.097  1.0164   250    1
## s_k[3]     0.260  0.0014 0.021  0.2580   247    1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># launch_shinystan(stan.fit)</span>

<span class="co"># Extraction --------------------------------------------------------------</span>
alpha &lt;-<span class="st"> </span><span class="kw">extract</span>(stan.fit, <span class="dt">pars =</span> <span class="st">'alpha_tk'</span>)[[<span class="dv">1</span>]]
gamma &lt;-<span class="st"> </span><span class="kw">extract</span>(stan.fit, <span class="dt">pars =</span> <span class="st">'gamma_tk'</span>)[[<span class="dv">1</span>]]
zstar &lt;-<span class="st"> </span><span class="kw">extract</span>(stan.fit, <span class="dt">pars =</span> <span class="st">'zstar_t'</span>)[[<span class="dv">1</span>]]
hatx  &lt;-<span class="st"> </span><span class="kw">extract</span>(stan.fit, <span class="dt">pars =</span> <span class="st">'hatx_t'</span>)[[<span class="dv">1</span>]]</code></pre></div>
<p>While mixing and convergence is very good, which is expected since we are dealing with data generated exactly as assumed by the model, we note that regression parameters for latent states perform worse than other parameters. One possible reason is that softmax is invarian to chance in location, thus the parameters of a multinomial regression do not have a natural location and become harder to estimate.</p>
<p>We want to assess if the hidden states were recovered correctly by our software. Unfortunately, due to the label switching problem, the states generated under the labels 1 to 3 were recovered in inverse order. In consequence, we decide to relabel the data based on best fit. This would not prove to be a problem with real data since the hidden states are never observed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Relabelling (ugly hack edition) -----------------------------------------</span>
dataset$zrelab &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, T)

hard &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span>:T.length, function(t, med) {
  <span class="kw">which.max</span>(med[t, ])
}, <span class="dt">med =</span> <span class="kw">apply</span>(alpha, <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>),
                    function(x) {
                      <span class="kw">quantile</span>(x, <span class="kw">c</span>(<span class="fl">0.50</span>)) }))

tab &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="dt">hard =</span> hard, <span class="dt">original =</span> dataset$z)

for (k in <span class="dv">1</span>:K) {
  dataset$zrelab[<span class="kw">which</span>(dataset$z ==<span class="st"> </span>k)] &lt;-<span class="st"> </span><span class="kw">which.max</span>(tab[, k])
}

<span class="kw">print</span>(<span class="st">&quot;Label re-imputation (relabeling due to switching labels)&quot;</span>)</code></pre></div>
<pre><code>## [1] &quot;Label re-imputation (relabeling due to switching labels)&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(<span class="dt">new =</span> dataset$zrelab, <span class="dt">original =</span> dataset$z)</code></pre></div>
<pre><code>##    original
## new   1   2   3
##   1   0   0 102
##   2   0 108   0
##   3  90   0   0</code></pre>
<p>Point estimates and credibility intervals are provided by rstan’s<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> <code>{r}summary</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Estimation summary ------------------------------------------------------</span>
<span class="kw">print</span>(<span class="st">&quot;Estimated initial state probabilities&quot;</span>)</code></pre></div>
<pre><code>## [1] &quot;Estimated initial state probabilities&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(stan.fit,
        <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">'p_1k'</span>),
        <span class="dt">probs =</span> <span class="kw">c</span>(<span class="fl">0.10</span>, <span class="fl">0.50</span>, <span class="fl">0.90</span>))$summary[, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>)]</code></pre></div>
<pre><code>##         mean   sd   10%  50%  90%
## p_1k[1] 0.26 0.22 0.018 0.23 0.58
## p_1k[2] 0.25 0.20 0.044 0.20 0.56
## p_1k[3] 0.49 0.23 0.200 0.50 0.81</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="st">&quot;Estimated probabilities in the transition matrix&quot;</span>)</code></pre></div>
<pre><code>## [1] &quot;Estimated probabilities in the transition matrix&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(stan.fit,
        <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">'A_ij'</span>),
        <span class="dt">probs =</span> <span class="kw">c</span>(<span class="fl">0.10</span>, <span class="fl">0.50</span>, <span class="fl">0.90</span>))$summary[, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>)]</code></pre></div>
<pre><code>##             mean     sd   10%  50%  90%
## A_ij[1,1]   0.26 0.2160 0.018 0.23 0.58
## A_ij[1,2]   0.25 0.1965 0.044 0.20 0.56
## A_ij[1,3]   0.49 0.2313 0.200 0.50 0.81
## A_ij[2,1]   0.33 0.0208 0.307 0.33 0.36
## A_ij[2,2]   0.36 0.0211 0.334 0.36 0.38
## A_ij[2,3]   0.31 0.0169 0.288 0.31 0.33
## A_ij[3,1]   0.30 0.0474 0.238 0.30 0.36
## A_ij[3,2]   0.38 0.0530 0.304 0.38 0.44
## A_ij[3,3]   0.32 0.0403 0.274 0.32 0.38
## A_ij[4,1]   0.40 0.0667 0.319 0.40 0.49
## A_ij[4,2]   0.34 0.0635 0.258 0.33 0.41
## A_ij[4,3]   0.26 0.0388 0.215 0.26 0.32
## A_ij[5,1]   0.27 0.0559 0.200 0.27 0.34
## A_ij[5,2]   0.42 0.0634 0.345 0.43 0.50
## A_ij[5,3]   0.30 0.0519 0.239 0.30 0.37
## A_ij[6,1]   0.41 0.0662 0.332 0.41 0.50
## A_ij[6,2]   0.34 0.0618 0.264 0.34 0.42
## A_ij[6,3]   0.25 0.0386 0.198 0.25 0.30
## A_ij[7,1]   0.36 0.0551 0.290 0.36 0.43
## A_ij[7,2]   0.32 0.0493 0.257 0.32 0.38
## A_ij[7,3]   0.32 0.0468 0.259 0.31 0.38
## A_ij[8,1]   0.46 0.1170 0.314 0.46 0.61
## A_ij[8,2]   0.18 0.0699 0.104 0.17 0.28
## A_ij[8,3]   0.36 0.0975 0.227 0.35 0.48
## A_ij[9,1]   0.46 0.0711 0.370 0.46 0.55
## A_ij[9,2]   0.28 0.0605 0.203 0.28 0.36
## A_ij[9,3]   0.26 0.0439 0.206 0.26 0.31
## A_ij[10,1]  0.38 0.0399 0.327 0.38 0.43
## A_ij[10,2]  0.30 0.0346 0.253 0.29 0.34
## A_ij[10,3]  0.33 0.0311 0.285 0.33 0.37
## A_ij[11,1]  0.33 0.0901 0.205 0.33 0.45
## A_ij[11,2]  0.25 0.0763 0.163 0.24 0.35
## A_ij[11,3]  0.42 0.0905 0.296 0.41 0.53
## A_ij[12,1]  0.51 0.0848 0.411 0.50 0.62
## A_ij[12,2]  0.23 0.0632 0.162 0.23 0.31
## A_ij[12,3]  0.26 0.0555 0.182 0.25 0.33
## A_ij[13,1]  0.41 0.0709 0.328 0.41 0.52
## A_ij[13,2]  0.28 0.0628 0.201 0.28 0.36
## A_ij[13,3]  0.31 0.0496 0.242 0.31 0.38
## A_ij[14,1]  0.37 0.0435 0.310 0.37 0.43
## A_ij[14,2]  0.30 0.0378 0.258 0.30 0.35
## A_ij[14,3]  0.33 0.0371 0.284 0.33 0.38
## A_ij[15,1]  0.27 0.0424 0.220 0.27 0.33
## A_ij[15,2]  0.41 0.0477 0.341 0.41 0.46
## A_ij[15,3]  0.32 0.0394 0.280 0.32 0.38
## A_ij[16,1]  0.30 0.0389 0.249 0.30 0.35
## A_ij[16,2]  0.38 0.0417 0.324 0.38 0.43
## A_ij[16,3]  0.32 0.0331 0.287 0.32 0.37
## A_ij[17,1]  0.27 0.0415 0.221 0.27 0.33
## A_ij[17,2]  0.43 0.0463 0.367 0.44 0.49
## A_ij[17,3]  0.29 0.0376 0.241 0.29 0.34
## A_ij[18,1]  0.39 0.0467 0.329 0.38 0.44
## A_ij[18,2]  0.32 0.0437 0.271 0.32 0.38
## A_ij[18,3]  0.29 0.0308 0.256 0.29 0.33
## A_ij[19,1]  0.38 0.0471 0.322 0.38 0.44
## A_ij[19,2]  0.26 0.0360 0.216 0.26 0.31
## A_ij[19,3]  0.36 0.0418 0.304 0.36 0.41
## A_ij[20,1]  0.39 0.0448 0.333 0.39 0.45
## A_ij[20,2]  0.26 0.0331 0.215 0.25 0.30
## A_ij[20,3]  0.36 0.0391 0.305 0.36 0.40
## A_ij[21,1]  0.39 0.0590 0.316 0.39 0.48
## A_ij[21,2]  0.31 0.0516 0.236 0.31 0.37
## A_ij[21,3]  0.30 0.0464 0.244 0.30 0.36
## A_ij[22,1]  0.40 0.0609 0.328 0.40 0.48
## A_ij[22,2]  0.29 0.0500 0.230 0.29 0.35
## A_ij[22,3]  0.31 0.0493 0.251 0.31 0.38
## A_ij[23,1]  0.28 0.0472 0.225 0.28 0.35
## A_ij[23,2]  0.40 0.0517 0.330 0.40 0.47
## A_ij[23,3]  0.32 0.0424 0.265 0.32 0.38
## A_ij[24,1]  0.34 0.0934 0.222 0.33 0.46
## A_ij[24,2]  0.27 0.0828 0.175 0.26 0.37
## A_ij[24,3]  0.39 0.0898 0.274 0.40 0.50
## A_ij[25,1]  0.34 0.0623 0.262 0.33 0.42
## A_ij[25,2]  0.38 0.0609 0.309 0.38 0.46
## A_ij[25,3]  0.28 0.0471 0.220 0.27 0.34
## A_ij[26,1]  0.33 0.0615 0.246 0.32 0.42
## A_ij[26,2]  0.32 0.0623 0.255 0.32 0.41
## A_ij[26,3]  0.35 0.0528 0.277 0.35 0.42
## A_ij[27,1]  0.43 0.0667 0.355 0.43 0.52
## A_ij[27,2]  0.29 0.0574 0.224 0.29 0.37
## A_ij[27,3]  0.27 0.0431 0.222 0.27 0.33
## A_ij[28,1]  0.39 0.0562 0.321 0.39 0.46
## A_ij[28,2]  0.25 0.0449 0.202 0.25 0.31
## A_ij[28,3]  0.36 0.0482 0.292 0.36 0.42
## A_ij[29,1]  0.46 0.0609 0.389 0.46 0.53
## A_ij[29,2]  0.24 0.0440 0.191 0.24 0.30
## A_ij[29,3]  0.30 0.0453 0.246 0.30 0.36
## A_ij[30,1]  0.30 0.0734 0.204 0.29 0.40
## A_ij[30,2]  0.31 0.0766 0.223 0.30 0.42
## A_ij[30,3]  0.39 0.0668 0.308 0.39 0.48
## A_ij[31,1]  0.21 0.0567 0.139 0.21 0.28
## A_ij[31,2]  0.37 0.0777 0.270 0.36 0.47
## A_ij[31,3]  0.42 0.0654 0.337 0.42 0.51
## A_ij[32,1]  0.31 0.0617 0.230 0.30 0.39
## A_ij[32,2]  0.43 0.0642 0.347 0.43 0.50
## A_ij[32,3]  0.26 0.0451 0.205 0.27 0.32
## A_ij[33,1]  0.23 0.0745 0.141 0.22 0.34
## A_ij[33,2]  0.46 0.0918 0.349 0.46 0.58
## A_ij[33,3]  0.30 0.0746 0.215 0.30 0.41
## A_ij[34,1]  0.34 0.0554 0.277 0.34 0.42
## A_ij[34,2]  0.37 0.0535 0.312 0.37 0.44
## A_ij[34,3]  0.28 0.0418 0.229 0.28 0.33
## A_ij[35,1]  0.30 0.0268 0.270 0.30 0.34
## A_ij[35,2]  0.33 0.0279 0.300 0.33 0.37
## A_ij[35,3]  0.36 0.0244 0.334 0.36 0.40
## A_ij[36,1]  0.33 0.0265 0.293 0.33 0.36
## A_ij[36,2]  0.30 0.0248 0.277 0.30 0.34
## A_ij[36,3]  0.37 0.0222 0.339 0.37 0.40
## A_ij[37,1]  0.26 0.0880 0.146 0.25 0.39
## A_ij[37,2]  0.40 0.1033 0.275 0.39 0.55
## A_ij[37,3]  0.33 0.0874 0.228 0.33 0.45
## A_ij[38,1]  0.39 0.0997 0.261 0.39 0.52
## A_ij[38,2]  0.24 0.0746 0.156 0.23 0.35
## A_ij[38,3]  0.37 0.0915 0.253 0.36 0.49
## A_ij[39,1]  0.26 0.0637 0.186 0.26 0.35
## A_ij[39,2]  0.32 0.0713 0.233 0.32 0.42
## A_ij[39,3]  0.41 0.0697 0.325 0.41 0.50
## A_ij[40,1]  0.26 0.1002 0.147 0.25 0.39
## A_ij[40,2]  0.53 0.1161 0.377 0.53 0.66
## A_ij[40,3]  0.20 0.0707 0.117 0.20 0.30
## A_ij[41,1]  0.39 0.0515 0.323 0.38 0.45
## A_ij[41,2]  0.25 0.0376 0.200 0.24 0.29
## A_ij[41,3]  0.37 0.0456 0.309 0.37 0.43
## A_ij[42,1]  0.43 0.1011 0.306 0.42 0.58
## A_ij[42,2]  0.18 0.0589 0.115 0.17 0.26
## A_ij[42,3]  0.38 0.0886 0.272 0.38 0.49
## A_ij[43,1]  0.40 0.0396 0.353 0.40 0.46
## A_ij[43,2]  0.27 0.0319 0.228 0.27 0.31
## A_ij[43,3]  0.33 0.0318 0.286 0.33 0.37
## A_ij[44,1]  0.31 0.0621 0.224 0.30 0.39
## A_ij[44,2]  0.29 0.0596 0.213 0.29 0.37
## A_ij[44,3]  0.40 0.0628 0.316 0.40 0.49
## A_ij[45,1]  0.43 0.0559 0.358 0.43 0.50
## A_ij[45,2]  0.25 0.0407 0.205 0.25 0.31
## A_ij[45,3]  0.32 0.0443 0.264 0.32 0.38
## A_ij[46,1]  0.27 0.0483 0.213 0.27 0.34
## A_ij[46,2]  0.41 0.0537 0.340 0.41 0.48
## A_ij[46,3]  0.32 0.0438 0.264 0.31 0.38
## A_ij[47,1]  0.27 0.0686 0.192 0.26 0.36
## A_ij[47,2]  0.27 0.0665 0.187 0.27 0.35
## A_ij[47,3]  0.46 0.0700 0.368 0.45 0.55
## A_ij[48,1]  0.45 0.0899 0.322 0.45 0.56
## A_ij[48,2]  0.25 0.0655 0.165 0.24 0.33
## A_ij[48,3]  0.31 0.0716 0.225 0.30 0.40
## A_ij[49,1]  0.32 0.0663 0.234 0.31 0.41
## A_ij[49,2]  0.30 0.0641 0.215 0.30 0.38
## A_ij[49,3]  0.39 0.0617 0.311 0.38 0.47
## A_ij[50,1]  0.43 0.0917 0.316 0.42 0.54
## A_ij[50,2]  0.35 0.0859 0.244 0.34 0.46
## A_ij[50,3]  0.22 0.0499 0.154 0.22 0.29
## A_ij[51,1]  0.37 0.0533 0.310 0.37 0.44
## A_ij[51,2]  0.27 0.0454 0.220 0.27 0.33
## A_ij[51,3]  0.36 0.0459 0.296 0.36 0.41
## A_ij[52,1]  0.29 0.0198 0.267 0.29 0.32
## A_ij[52,2]  0.36 0.0209 0.338 0.36 0.39
## A_ij[52,3]  0.34 0.0179 0.320 0.34 0.37
## A_ij[53,1]  0.41 0.0688 0.325 0.40 0.51
## A_ij[53,2]  0.22 0.0452 0.160 0.21 0.27
## A_ij[53,3]  0.37 0.0605 0.304 0.38 0.45
## A_ij[54,1]  0.34 0.0522 0.278 0.35 0.42
## A_ij[54,2]  0.34 0.0526 0.274 0.34 0.41
## A_ij[54,3]  0.32 0.0389 0.268 0.32 0.37
## A_ij[55,1]  0.45 0.1157 0.329 0.44 0.61
## A_ij[55,2]  0.31 0.1014 0.185 0.31 0.43
## A_ij[55,3]  0.24 0.0740 0.148 0.23 0.34
## A_ij[56,1]  0.17 0.0605 0.094 0.16 0.26
## A_ij[56,2]  0.50 0.1012 0.366 0.49 0.62
## A_ij[56,3]  0.34 0.0840 0.231 0.33 0.44
## A_ij[57,1]  0.30 0.0471 0.245 0.30 0.36
## A_ij[57,2]  0.30 0.0470 0.249 0.30 0.36
## A_ij[57,3]  0.40 0.0399 0.345 0.40 0.45
## A_ij[58,1]  0.27 0.0865 0.164 0.26 0.39
## A_ij[58,2]  0.45 0.0994 0.320 0.46 0.57
## A_ij[58,3]  0.28 0.0769 0.186 0.28 0.38
## A_ij[59,1]  0.32 0.0307 0.280 0.32 0.35
## A_ij[59,2]  0.31 0.0298 0.276 0.31 0.35
## A_ij[59,3]  0.37 0.0247 0.344 0.37 0.41
## A_ij[60,1]  0.32 0.0501 0.259 0.32 0.37
## A_ij[60,2]  0.27 0.0438 0.217 0.27 0.33
## A_ij[60,3]  0.41 0.0443 0.352 0.41 0.47
## A_ij[61,1]  0.25 0.0447 0.192 0.25 0.31
## A_ij[61,2]  0.39 0.0564 0.324 0.40 0.46
## A_ij[61,3]  0.36 0.0426 0.301 0.36 0.41
## A_ij[62,1]  0.42 0.0395 0.366 0.41 0.46
## A_ij[62,2]  0.28 0.0318 0.241 0.28 0.32
## A_ij[62,3]  0.31 0.0294 0.271 0.30 0.35
## A_ij[63,1]  0.22 0.0644 0.142 0.21 0.31
## A_ij[63,2]  0.48 0.0839 0.358 0.48 0.58
## A_ij[63,3]  0.31 0.0677 0.228 0.30 0.41
## A_ij[64,1]  0.23 0.0444 0.170 0.23 0.28
## A_ij[64,2]  0.45 0.0584 0.380 0.45 0.53
## A_ij[64,3]  0.32 0.0473 0.259 0.32 0.38
## A_ij[65,1]  0.33 0.0361 0.283 0.32 0.38
## A_ij[65,2]  0.32 0.0357 0.274 0.32 0.37
## A_ij[65,3]  0.35 0.0285 0.312 0.35 0.39
## A_ij[66,1]  0.35 0.0675 0.270 0.35 0.44
## A_ij[66,2]  0.25 0.0534 0.185 0.25 0.33
## A_ij[66,3]  0.40 0.0577 0.320 0.40 0.46
## A_ij[67,1]  0.30 0.0201 0.275 0.30 0.33
## A_ij[67,2]  0.34 0.0205 0.315 0.34 0.37
## A_ij[67,3]  0.36 0.0174 0.335 0.36 0.38
## A_ij[68,1]  0.27 0.0635 0.183 0.26 0.35
## A_ij[68,2]  0.33 0.0736 0.242 0.32 0.43
## A_ij[68,3]  0.40 0.0635 0.326 0.40 0.49
## A_ij[69,1]  0.26 0.0468 0.201 0.26 0.32
## A_ij[69,2]  0.46 0.0537 0.384 0.46 0.52
## A_ij[69,3]  0.28 0.0421 0.230 0.28 0.34
## A_ij[70,1]  0.32 0.0635 0.239 0.31 0.41
## A_ij[70,2]  0.33 0.0652 0.248 0.33 0.42
## A_ij[70,3]  0.35 0.0512 0.280 0.35 0.42
## A_ij[71,1]  0.35 0.0566 0.285 0.35 0.42
## A_ij[71,2]  0.39 0.0565 0.323 0.38 0.46
## A_ij[71,3]  0.26 0.0368 0.209 0.26 0.31
## A_ij[72,1]  0.45 0.0580 0.382 0.45 0.53
## A_ij[72,2]  0.24 0.0429 0.191 0.24 0.30
## A_ij[72,3]  0.30 0.0430 0.251 0.30 0.36
## A_ij[73,1]  0.27 0.0503 0.215 0.27 0.34
## A_ij[73,2]  0.32 0.0535 0.257 0.33 0.39
## A_ij[73,3]  0.40 0.0505 0.342 0.40 0.47
## A_ij[74,1]  0.29 0.0724 0.204 0.28 0.38
## A_ij[74,2]  0.43 0.0809 0.324 0.43 0.53
## A_ij[74,3]  0.29 0.0652 0.211 0.28 0.37
## A_ij[75,1]  0.33 0.0365 0.281 0.33 0.38
## A_ij[75,2]  0.32 0.0366 0.282 0.32 0.37
## A_ij[75,3]  0.34 0.0298 0.305 0.34 0.38
## A_ij[76,1]  0.28 0.0417 0.233 0.29 0.33
## A_ij[76,2]  0.34 0.0453 0.285 0.34 0.39
## A_ij[76,3]  0.38 0.0405 0.330 0.38 0.43
## A_ij[77,1]  0.32 0.0865 0.212 0.32 0.44
## A_ij[77,2]  0.39 0.0933 0.274 0.38 0.52
## A_ij[77,3]  0.29 0.0679 0.205 0.28 0.38
## A_ij[78,1]  0.28 0.0525 0.210 0.28 0.35
## A_ij[78,2]  0.43 0.0578 0.359 0.44 0.51
## A_ij[78,3]  0.29 0.0455 0.227 0.28 0.34
## A_ij[79,1]  0.38 0.0285 0.339 0.38 0.41
## A_ij[79,2]  0.31 0.0258 0.280 0.31 0.34
## A_ij[79,3]  0.32 0.0213 0.290 0.32 0.35
## A_ij[80,1]  0.40 0.1027 0.276 0.38 0.55
## A_ij[80,2]  0.32 0.0931 0.205 0.32 0.45
## A_ij[80,3]  0.28 0.0761 0.188 0.27 0.38
## A_ij[81,1]  0.32 0.0885 0.203 0.31 0.44
## A_ij[81,2]  0.23 0.0701 0.141 0.22 0.32
## A_ij[81,3]  0.46 0.0866 0.335 0.45 0.57
## A_ij[82,1]  0.35 0.0337 0.308 0.35 0.40
## A_ij[82,2]  0.29 0.0309 0.253 0.29 0.33
## A_ij[82,3]  0.36 0.0291 0.317 0.36 0.39
## A_ij[83,1]  0.36 0.0360 0.319 0.36 0.41
## A_ij[83,2]  0.29 0.0304 0.251 0.29 0.33
## A_ij[83,3]  0.35 0.0326 0.305 0.35 0.39
## A_ij[84,1]  0.33 0.0413 0.273 0.33 0.38
## A_ij[84,2]  0.32 0.0387 0.274 0.32 0.37
## A_ij[84,3]  0.35 0.0380 0.304 0.35 0.40
## A_ij[85,1]  0.33 0.0410 0.279 0.33 0.39
## A_ij[85,2]  0.36 0.0403 0.312 0.36 0.41
## A_ij[85,3]  0.31 0.0348 0.265 0.30 0.35
## A_ij[86,1]  0.35 0.0500 0.289 0.35 0.42
## A_ij[86,2]  0.32 0.0470 0.254 0.32 0.38
## A_ij[86,3]  0.33 0.0400 0.278 0.33 0.38
## A_ij[87,1]  0.33 0.0936 0.208 0.32 0.46
## A_ij[87,2]  0.25 0.0813 0.162 0.24 0.35
## A_ij[87,3]  0.42 0.0891 0.301 0.42 0.52
## A_ij[88,1]  0.25 0.0759 0.156 0.24 0.36
## A_ij[88,2]  0.34 0.0869 0.226 0.34 0.46
## A_ij[88,3]  0.41 0.0841 0.307 0.40 0.52
## A_ij[89,1]  0.48 0.1038 0.332 0.47 0.61
## A_ij[89,2]  0.22 0.0702 0.136 0.22 0.31
## A_ij[89,3]  0.30 0.0819 0.205 0.29 0.42
## A_ij[90,1]  0.33 0.0527 0.272 0.33 0.40
## A_ij[90,2]  0.30 0.0466 0.245 0.30 0.36
## A_ij[90,3]  0.37 0.0466 0.305 0.37 0.43
## A_ij[91,1]  0.30 0.0817 0.201 0.30 0.41
## A_ij[91,2]  0.24 0.0680 0.155 0.23 0.33
## A_ij[91,3]  0.46 0.0788 0.358 0.47 0.56
## A_ij[92,1]  0.30 0.0357 0.261 0.31 0.35
## A_ij[92,2]  0.39 0.0390 0.344 0.39 0.44
## A_ij[92,3]  0.30 0.0303 0.264 0.30 0.34
## A_ij[93,1]  0.26 0.0568 0.194 0.26 0.33
## A_ij[93,2]  0.36 0.0655 0.268 0.35 0.44
## A_ij[93,3]  0.38 0.0514 0.318 0.38 0.45
## A_ij[94,1]  0.39 0.0463 0.333 0.39 0.45
## A_ij[94,2]  0.27 0.0365 0.232 0.27 0.32
## A_ij[94,3]  0.33 0.0376 0.282 0.33 0.38
## A_ij[95,1]  0.35 0.0693 0.262 0.35 0.45
## A_ij[95,2]  0.31 0.0649 0.222 0.30 0.40
## A_ij[95,3]  0.34 0.0580 0.271 0.34 0.42
## A_ij[96,1]  0.30 0.0789 0.203 0.30 0.40
## A_ij[96,2]  0.25 0.0690 0.165 0.24 0.34
## A_ij[96,3]  0.45 0.0770 0.344 0.44 0.55
## A_ij[97,1]  0.25 0.0512 0.185 0.24 0.31
## A_ij[97,2]  0.34 0.0593 0.265 0.34 0.42
## A_ij[97,3]  0.41 0.0541 0.344 0.41 0.48
## A_ij[98,1]  0.19 0.0807 0.094 0.18 0.29
## A_ij[98,2]  0.38 0.1166 0.228 0.37 0.52
## A_ij[98,3]  0.44 0.0988 0.300 0.44 0.57
## A_ij[99,1]  0.37 0.0561 0.294 0.37 0.44
## A_ij[99,2]  0.33 0.0534 0.263 0.32 0.40
## A_ij[99,3]  0.30 0.0418 0.248 0.30 0.35
## A_ij[100,1] 0.31 0.0290 0.273 0.31 0.35
## A_ij[100,2] 0.35 0.0296 0.316 0.35 0.39
## A_ij[100,3] 0.34 0.0260 0.302 0.33 0.37
## A_ij[101,1] 0.50 0.1174 0.346 0.51 0.66
## A_ij[101,2] 0.26 0.0999 0.143 0.26 0.39
## A_ij[101,3] 0.24 0.0682 0.151 0.24 0.33
## A_ij[102,1] 0.36 0.0843 0.263 0.36 0.47
## A_ij[102,2] 0.22 0.0610 0.150 0.21 0.30
## A_ij[102,3] 0.42 0.0782 0.319 0.42 0.51
## A_ij[103,1] 0.35 0.0686 0.262 0.34 0.45
## A_ij[103,2] 0.35 0.0674 0.259 0.35 0.43
## A_ij[103,3] 0.30 0.0553 0.241 0.30 0.38
## A_ij[104,1] 0.35 0.0775 0.251 0.34 0.44
## A_ij[104,2] 0.39 0.0764 0.291 0.39 0.49
## A_ij[104,3] 0.26 0.0536 0.193 0.26 0.34
## A_ij[105,1] 0.36 0.0424 0.310 0.36 0.42
## A_ij[105,2] 0.31 0.0376 0.264 0.31 0.36
## A_ij[105,3] 0.32 0.0365 0.279 0.32 0.37
## A_ij[106,1] 0.29 0.0555 0.217 0.29 0.36
## A_ij[106,2] 0.31 0.0578 0.236 0.31 0.39
## A_ij[106,3] 0.40 0.0572 0.314 0.39 0.47
## A_ij[107,1] 0.38 0.0482 0.316 0.38 0.43
## A_ij[107,2] 0.35 0.0460 0.293 0.35 0.40
## A_ij[107,3] 0.27 0.0324 0.231 0.28 0.31
## A_ij[108,1] 0.41 0.0585 0.335 0.41 0.49
## A_ij[108,2] 0.24 0.0418 0.194 0.24 0.30
## A_ij[108,3] 0.35 0.0482 0.285 0.35 0.41
## A_ij[109,1] 0.25 0.0855 0.154 0.24 0.37
## A_ij[109,2] 0.36 0.0963 0.236 0.36 0.49
## A_ij[109,3] 0.38 0.0862 0.272 0.39 0.50
## A_ij[110,1] 0.37 0.0509 0.309 0.37 0.44
## A_ij[110,2] 0.26 0.0412 0.214 0.26 0.32
## A_ij[110,3] 0.37 0.0455 0.309 0.37 0.43
## A_ij[111,1] 0.46 0.0786 0.356 0.46 0.56
## A_ij[111,2] 0.23 0.0552 0.167 0.22 0.30
## A_ij[111,3] 0.31 0.0607 0.240 0.31 0.39
## A_ij[112,1] 0.37 0.0658 0.288 0.37 0.46
## A_ij[112,2] 0.32 0.0587 0.253 0.32 0.40
## A_ij[112,3] 0.31 0.0546 0.240 0.30 0.38
## A_ij[113,1] 0.43 0.0984 0.298 0.43 0.57
## A_ij[113,2] 0.33 0.0877 0.225 0.32 0.45
## A_ij[113,3] 0.24 0.0606 0.168 0.23 0.32
## A_ij[114,1] 0.18 0.0633 0.100 0.17 0.26
## A_ij[114,2] 0.53 0.0939 0.404 0.54 0.65
## A_ij[114,3] 0.29 0.0766 0.194 0.29 0.39
## A_ij[115,1] 0.36 0.0495 0.303 0.35 0.43
## A_ij[115,2] 0.36 0.0488 0.297 0.36 0.42
## A_ij[115,3] 0.28 0.0334 0.233 0.28 0.32
## A_ij[116,1] 0.28 0.0585 0.211 0.28 0.36
## A_ij[116,2] 0.43 0.0667 0.346 0.44 0.51
## A_ij[116,3] 0.28 0.0524 0.223 0.28 0.35
## A_ij[117,1] 0.37 0.0511 0.308 0.36 0.43
## A_ij[117,2] 0.35 0.0491 0.288 0.34 0.41
## A_ij[117,3] 0.28 0.0385 0.235 0.28 0.34
## A_ij[118,1] 0.42 0.0460 0.365 0.41 0.48
## A_ij[118,2] 0.29 0.0384 0.244 0.29 0.34
## A_ij[118,3] 0.29 0.0325 0.250 0.29 0.34
## A_ij[119,1] 0.20 0.0788 0.109 0.19 0.31
## A_ij[119,2] 0.41 0.1107 0.251 0.41 0.55
## A_ij[119,3] 0.39 0.1014 0.272 0.38 0.53
## A_ij[120,1] 0.29 0.0421 0.239 0.29 0.35
## A_ij[120,2] 0.38 0.0444 0.323 0.38 0.43
## A_ij[120,3] 0.33 0.0403 0.279 0.33 0.38
## A_ij[121,1] 0.32 0.0935 0.197 0.31 0.45
## A_ij[121,2] 0.36 0.0995 0.237 0.35 0.50
## A_ij[121,3] 0.32 0.0756 0.230 0.31 0.43
## A_ij[122,1] 0.30 0.0538 0.235 0.30 0.38
## A_ij[122,2] 0.30 0.0520 0.236 0.30 0.37
## A_ij[122,3] 0.40 0.0517 0.334 0.39 0.47
## A_ij[123,1] 0.29 0.0663 0.201 0.29 0.38
## A_ij[123,2] 0.36 0.0731 0.278 0.36 0.46
## A_ij[123,3] 0.35 0.0606 0.272 0.34 0.43
## A_ij[124,1] 0.21 0.0586 0.134 0.21 0.28
## A_ij[124,2] 0.49 0.0815 0.388 0.49 0.60
## A_ij[124,3] 0.30 0.0650 0.215 0.29 0.39
## A_ij[125,1] 0.19 0.0785 0.098 0.18 0.28
## A_ij[125,2] 0.47 0.1164 0.328 0.47 0.62
## A_ij[125,3] 0.35 0.0960 0.231 0.34 0.48
## A_ij[126,1] 0.32 0.0592 0.241 0.32 0.40
## A_ij[126,2] 0.26 0.0514 0.201 0.26 0.33
## A_ij[126,3] 0.42 0.0546 0.348 0.42 0.49
## A_ij[127,1] 0.27 0.0879 0.166 0.25 0.38
## A_ij[127,2] 0.43 0.1018 0.298 0.43 0.57
## A_ij[127,3] 0.30 0.0848 0.211 0.29 0.42
## A_ij[128,1] 0.30 0.0587 0.219 0.30 0.37
## A_ij[128,2] 0.35 0.0630 0.269 0.35 0.44
## A_ij[128,3] 0.35 0.0567 0.278 0.35 0.42
## A_ij[129,1] 0.39 0.0474 0.328 0.39 0.46
## A_ij[129,2] 0.28 0.0393 0.226 0.28 0.33
## A_ij[129,3] 0.33 0.0391 0.284 0.33 0.38
## A_ij[130,1] 0.50 0.1032 0.375 0.50 0.64
## A_ij[130,2] 0.27 0.0864 0.157 0.26 0.38
## A_ij[130,3] 0.23 0.0607 0.154 0.22 0.31
## A_ij[131,1] 0.36 0.0134 0.339 0.36 0.37
## A_ij[131,2] 0.32 0.0130 0.307 0.32 0.34
## A_ij[131,3] 0.32 0.0097 0.308 0.32 0.33
## A_ij[132,1] 0.47 0.0736 0.375 0.47 0.56
## A_ij[132,2] 0.25 0.0559 0.184 0.25 0.33
## A_ij[132,3] 0.28 0.0527 0.214 0.27 0.35
## A_ij[133,1] 0.28 0.0294 0.243 0.28 0.32
## A_ij[133,2] 0.40 0.0312 0.353 0.40 0.43
## A_ij[133,3] 0.32 0.0270 0.288 0.32 0.36
## A_ij[134,1] 0.41 0.0558 0.341 0.41 0.49
## A_ij[134,2] 0.27 0.0437 0.220 0.26 0.32
## A_ij[134,3] 0.32 0.0441 0.260 0.31 0.37
## A_ij[135,1] 0.42 0.0493 0.353 0.41 0.48
## A_ij[135,2] 0.27 0.0403 0.222 0.27 0.33
## A_ij[135,3] 0.31 0.0373 0.262 0.31 0.36
## A_ij[136,1] 0.38 0.0449 0.329 0.38 0.44
## A_ij[136,2] 0.32 0.0431 0.266 0.32 0.38
## A_ij[136,3] 0.30 0.0290 0.262 0.30 0.34
## A_ij[137,1] 0.48 0.0928 0.361 0.47 0.61
## A_ij[137,2] 0.27 0.0750 0.182 0.26 0.38
## A_ij[137,3] 0.25 0.0603 0.171 0.25 0.33
## A_ij[138,1] 0.18 0.0740 0.089 0.16 0.28
## A_ij[138,2] 0.41 0.1189 0.261 0.40 0.56
## A_ij[138,3] 0.42 0.0995 0.289 0.42 0.54
## A_ij[139,1] 0.24 0.0514 0.175 0.24 0.31
## A_ij[139,2] 0.47 0.0649 0.384 0.46 0.55
## A_ij[139,3] 0.29 0.0514 0.227 0.29 0.37
## A_ij[140,1] 0.40 0.0736 0.307 0.40 0.51
## A_ij[140,2] 0.25 0.0549 0.187 0.25 0.32
## A_ij[140,3] 0.35 0.0646 0.267 0.34 0.43
## A_ij[141,1] 0.49 0.0777 0.396 0.48 0.59
## A_ij[141,2] 0.24 0.0581 0.172 0.24 0.32
## A_ij[141,3] 0.27 0.0537 0.209 0.26 0.34
## A_ij[142,1] 0.26 0.0480 0.206 0.26 0.32
## A_ij[142,2] 0.34 0.0543 0.274 0.34 0.41
## A_ij[142,3] 0.39 0.0493 0.334 0.39 0.46
## A_ij[143,1] 0.46 0.0784 0.360 0.46 0.57
## A_ij[143,2] 0.23 0.0549 0.166 0.23 0.31
## A_ij[143,3] 0.31 0.0618 0.234 0.31 0.39
## A_ij[144,1] 0.34 0.0853 0.236 0.33 0.46
## A_ij[144,2] 0.27 0.0747 0.171 0.26 0.37
## A_ij[144,3] 0.39 0.0774 0.288 0.38 0.49
## A_ij[145,1] 0.22 0.0631 0.143 0.21 0.30
## A_ij[145,2] 0.40 0.0840 0.299 0.39 0.52
## A_ij[145,3] 0.38 0.0751 0.282 0.38 0.49
## A_ij[146,1] 0.40 0.0950 0.275 0.39 0.53
## A_ij[146,2] 0.23 0.0697 0.151 0.22 0.32
## A_ij[146,3] 0.38 0.0830 0.267 0.38 0.48
## A_ij[147,1] 0.32 0.0168 0.298 0.32 0.34
## A_ij[147,2] 0.37 0.0162 0.345 0.37 0.39
## A_ij[147,3] 0.32 0.0138 0.299 0.32 0.33
## A_ij[148,1] 0.36 0.0811 0.249 0.35 0.46
## A_ij[148,2] 0.22 0.0596 0.154 0.22 0.30
## A_ij[148,3] 0.42 0.0766 0.320 0.42 0.51
## A_ij[149,1] 0.39 0.0325 0.350 0.39 0.43
## A_ij[149,2] 0.30 0.0296 0.261 0.30 0.34
## A_ij[149,3] 0.31 0.0225 0.280 0.31 0.34
## A_ij[150,1] 0.36 0.0442 0.311 0.36 0.42
## A_ij[150,2] 0.27 0.0355 0.226 0.27 0.32
## A_ij[150,3] 0.37 0.0393 0.321 0.37 0.42
## A_ij[151,1] 0.30 0.0343 0.256 0.30 0.34
## A_ij[151,2] 0.37 0.0387 0.320 0.37 0.42
## A_ij[151,3] 0.33 0.0290 0.289 0.33 0.37
## A_ij[152,1] 0.29 0.0453 0.233 0.29 0.35
## A_ij[152,2] 0.43 0.0489 0.357 0.43 0.49
## A_ij[152,3] 0.28 0.0373 0.236 0.28 0.33
## A_ij[153,1] 0.34 0.0266 0.309 0.34 0.38
## A_ij[153,2] 0.32 0.0250 0.287 0.32 0.36
## A_ij[153,3] 0.34 0.0232 0.308 0.34 0.37
## A_ij[154,1] 0.20 0.0537 0.138 0.20 0.28
## A_ij[154,2] 0.45 0.0750 0.352 0.44 0.55
## A_ij[154,3] 0.35 0.0651 0.269 0.35 0.44
## A_ij[155,1] 0.49 0.0898 0.378 0.48 0.61
## A_ij[155,2] 0.27 0.0742 0.179 0.26 0.36
## A_ij[155,3] 0.24 0.0535 0.178 0.24 0.32
## A_ij[156,1] 0.39 0.0467 0.327 0.39 0.45
## A_ij[156,2] 0.30 0.0422 0.255 0.30 0.36
## A_ij[156,3] 0.30 0.0332 0.262 0.30 0.35
## A_ij[157,1] 0.39 0.0711 0.308 0.39 0.48
## A_ij[157,2] 0.35 0.0690 0.262 0.35 0.43
## A_ij[157,3] 0.26 0.0412 0.210 0.26 0.31
## A_ij[158,1] 0.28 0.0642 0.190 0.27 0.36
## A_ij[158,2] 0.35 0.0719 0.255 0.35 0.45
## A_ij[158,3] 0.37 0.0685 0.286 0.37 0.46
## A_ij[159,1] 0.39 0.0787 0.291 0.39 0.51
## A_ij[159,2] 0.31 0.0679 0.215 0.31 0.40
## A_ij[159,3] 0.30 0.0638 0.227 0.29 0.39
## A_ij[160,1] 0.35 0.0205 0.320 0.35 0.37
## A_ij[160,2] 0.31 0.0183 0.290 0.31 0.34
## A_ij[160,3] 0.34 0.0183 0.319 0.34 0.36
## A_ij[161,1] 0.41 0.1216 0.261 0.41 0.57
## A_ij[161,2] 0.20 0.0776 0.111 0.19 0.31
## A_ij[161,3] 0.39 0.1062 0.249 0.38 0.52
## A_ij[162,1] 0.39 0.0783 0.300 0.38 0.49
## A_ij[162,2] 0.37 0.0770 0.273 0.38 0.46
## A_ij[162,3] 0.24 0.0442 0.185 0.24 0.30
## A_ij[163,1] 0.33 0.0197 0.308 0.33 0.36
## A_ij[163,2] 0.34 0.0186 0.311 0.34 0.36
## A_ij[163,3] 0.33 0.0179 0.310 0.33 0.36
## A_ij[164,1] 0.42 0.0503 0.354 0.42 0.48
## A_ij[164,2] 0.30 0.0446 0.241 0.29 0.35
## A_ij[164,3] 0.29 0.0330 0.243 0.29 0.33
## A_ij[165,1] 0.27 0.0460 0.209 0.27 0.33
## A_ij[165,2] 0.42 0.0520 0.354 0.42 0.48
## A_ij[165,3] 0.31 0.0446 0.256 0.31 0.37
## A_ij[166,1] 0.29 0.0430 0.239 0.29 0.36
## A_ij[166,2] 0.36 0.0455 0.309 0.36 0.43
## A_ij[166,3] 0.34 0.0421 0.291 0.34 0.39
## A_ij[167,1] 0.28 0.0626 0.200 0.28 0.37
## A_ij[167,2] 0.34 0.0707 0.251 0.33 0.44
## A_ij[167,3] 0.38 0.0577 0.307 0.38 0.46
## A_ij[168,1] 0.31 0.0527 0.251 0.31 0.38
## A_ij[168,2] 0.31 0.0533 0.247 0.31 0.38
## A_ij[168,3] 0.37 0.0429 0.317 0.38 0.43
## A_ij[169,1] 0.28 0.0710 0.196 0.27 0.37
## A_ij[169,2] 0.30 0.0731 0.217 0.29 0.39
## A_ij[169,3] 0.42 0.0727 0.333 0.42 0.51
## A_ij[170,1] 0.29 0.0637 0.220 0.29 0.37
## A_ij[170,2] 0.34 0.0676 0.254 0.34 0.43
## A_ij[170,3] 0.36 0.0548 0.294 0.36 0.44
## A_ij[171,1] 0.43 0.0970 0.305 0.43 0.56
## A_ij[171,2] 0.25 0.0786 0.160 0.23 0.36
## A_ij[171,3] 0.32 0.0729 0.224 0.32 0.41
## A_ij[172,1] 0.24 0.0451 0.181 0.24 0.29
## A_ij[172,2] 0.36 0.0563 0.293 0.36 0.44
## A_ij[172,3] 0.40 0.0465 0.337 0.40 0.46
## A_ij[173,1] 0.35 0.0402 0.302 0.35 0.41
## A_ij[173,2] 0.30 0.0344 0.257 0.30 0.35
## A_ij[173,3] 0.35 0.0352 0.305 0.35 0.39
## A_ij[174,1] 0.33 0.0592 0.256 0.32 0.41
## A_ij[174,2] 0.28 0.0529 0.214 0.28 0.35
## A_ij[174,3] 0.39 0.0551 0.325 0.39 0.46
## A_ij[175,1] 0.35 0.0302 0.310 0.35 0.38
## A_ij[175,2] 0.35 0.0297 0.318 0.35 0.39
## A_ij[175,3] 0.30 0.0226 0.270 0.30 0.33
## A_ij[176,1] 0.38 0.1175 0.228 0.37 0.55
## A_ij[176,2] 0.35 0.1132 0.210 0.35 0.49
## A_ij[176,3] 0.27 0.0856 0.176 0.25 0.38
## A_ij[177,1] 0.25 0.0535 0.177 0.25 0.31
## A_ij[177,2] 0.34 0.0650 0.260 0.34 0.42
## A_ij[177,3] 0.41 0.0544 0.344 0.41 0.48
## A_ij[178,1] 0.42 0.0452 0.369 0.42 0.48
## A_ij[178,2] 0.25 0.0336 0.210 0.25 0.29
## A_ij[178,3] 0.33 0.0360 0.279 0.32 0.37
## A_ij[179,1] 0.38 0.0268 0.342 0.37 0.41
## A_ij[179,2] 0.31 0.0244 0.275 0.30 0.34
## A_ij[179,3] 0.32 0.0206 0.292 0.32 0.34
## A_ij[180,1] 0.40 0.0664 0.326 0.40 0.50
## A_ij[180,2] 0.29 0.0569 0.221 0.29 0.37
## A_ij[180,3] 0.30 0.0513 0.242 0.30 0.37
## A_ij[181,1] 0.24 0.0677 0.155 0.23 0.32
## A_ij[181,2] 0.51 0.0815 0.399 0.52 0.61
## A_ij[181,3] 0.25 0.0579 0.178 0.25 0.33
## A_ij[182,1] 0.28 0.0434 0.224 0.28 0.33
## A_ij[182,2] 0.31 0.0460 0.258 0.31 0.37
## A_ij[182,3] 0.41 0.0395 0.360 0.40 0.46
## A_ij[183,1] 0.44 0.0815 0.332 0.43 0.55
## A_ij[183,2] 0.28 0.0671 0.194 0.29 0.37
## A_ij[183,3] 0.28 0.0602 0.213 0.28 0.35
## A_ij[184,1] 0.36 0.0473 0.300 0.36 0.43
## A_ij[184,2] 0.32 0.0427 0.267 0.32 0.38
## A_ij[184,3] 0.32 0.0388 0.266 0.31 0.36
## A_ij[185,1] 0.31 0.0348 0.262 0.31 0.35
## A_ij[185,2] 0.38 0.0384 0.328 0.38 0.43
## A_ij[185,3] 0.32 0.0295 0.281 0.31 0.36
## A_ij[186,1] 0.45 0.0768 0.354 0.45 0.55
## A_ij[186,2] 0.22 0.0516 0.161 0.22 0.29
## A_ij[186,3] 0.32 0.0627 0.250 0.32 0.41
## A_ij[187,1] 0.30 0.0661 0.224 0.30 0.39
## A_ij[187,2] 0.38 0.0711 0.283 0.38 0.47
## A_ij[187,3] 0.32 0.0557 0.248 0.31 0.39
## A_ij[188,1] 0.34 0.0420 0.280 0.33 0.40
## A_ij[188,2] 0.29 0.0361 0.242 0.29 0.34
## A_ij[188,3] 0.38 0.0382 0.331 0.37 0.42
## A_ij[189,1] 0.39 0.0378 0.342 0.39 0.44
## A_ij[189,2] 0.27 0.0317 0.235 0.27 0.32
## A_ij[189,3] 0.34 0.0305 0.296 0.34 0.37
## A_ij[190,1] 0.36 0.0469 0.305 0.37 0.43
## A_ij[190,2] 0.30 0.0402 0.253 0.30 0.36
## A_ij[190,3] 0.33 0.0410 0.282 0.33 0.39
## A_ij[191,1] 0.14 0.0729 0.056 0.13 0.23
## A_ij[191,2] 0.56 0.1324 0.393 0.56 0.73
## A_ij[191,3] 0.30 0.1112 0.171 0.30 0.46
## A_ij[192,1] 0.19 0.0711 0.105 0.18 0.28
## A_ij[192,2] 0.46 0.1048 0.327 0.46 0.59
## A_ij[192,3] 0.36 0.0934 0.232 0.36 0.48
## A_ij[193,1] 0.24 0.0473 0.186 0.24 0.30
## A_ij[193,2] 0.37 0.0564 0.306 0.37 0.44
## A_ij[193,3] 0.38 0.0483 0.313 0.38 0.44
## A_ij[194,1] 0.26 0.0399 0.214 0.26 0.32
## A_ij[194,2] 0.38 0.0456 0.325 0.38 0.44
## A_ij[194,3] 0.35 0.0395 0.303 0.35 0.41
## A_ij[195,1] 0.42 0.1016 0.306 0.42 0.56
## A_ij[195,2] 0.36 0.0961 0.244 0.36 0.50
## A_ij[195,3] 0.21 0.0537 0.140 0.21 0.28
## A_ij[196,1] 0.28 0.0523 0.217 0.28 0.34
## A_ij[196,2] 0.30 0.0519 0.229 0.29 0.36
## A_ij[196,3] 0.42 0.0489 0.364 0.42 0.49
## A_ij[197,1] 0.26 0.0463 0.197 0.25 0.32
## A_ij[197,2] 0.40 0.0543 0.331 0.40 0.47
## A_ij[197,3] 0.34 0.0462 0.284 0.34 0.40
## A_ij[198,1] 0.34 0.0433 0.283 0.34 0.40
## A_ij[198,2] 0.32 0.0393 0.268 0.32 0.37
## A_ij[198,3] 0.34 0.0392 0.294 0.34 0.39
## A_ij[199,1] 0.42 0.0565 0.344 0.41 0.49
## A_ij[199,2] 0.31 0.0520 0.249 0.31 0.37
## A_ij[199,3] 0.27 0.0336 0.226 0.27 0.32
## A_ij[200,1] 0.29 0.0536 0.221 0.28 0.36
## A_ij[200,2] 0.40 0.0600 0.323 0.40 0.48
## A_ij[200,3] 0.32 0.0494 0.259 0.31 0.38
## A_ij[201,1] 0.35 0.0585 0.273 0.35 0.43
## A_ij[201,2] 0.30 0.0544 0.235 0.29 0.37
## A_ij[201,3] 0.35 0.0478 0.291 0.35 0.41
## A_ij[202,1] 0.37 0.0988 0.254 0.36 0.52
## A_ij[202,2] 0.33 0.0898 0.209 0.33 0.44
## A_ij[202,3] 0.30 0.0815 0.207 0.29 0.40
## A_ij[203,1] 0.43 0.0673 0.345 0.43 0.52
## A_ij[203,2] 0.25 0.0489 0.191 0.24 0.31
## A_ij[203,3] 0.32 0.0546 0.250 0.32 0.39
## A_ij[204,1] 0.24 0.0419 0.185 0.23 0.28
## A_ij[204,2] 0.39 0.0528 0.322 0.39 0.45
## A_ij[204,3] 0.38 0.0427 0.321 0.38 0.43
## A_ij[205,1] 0.30 0.0506 0.237 0.30 0.38
## A_ij[205,2] 0.38 0.0529 0.312 0.38 0.44
## A_ij[205,3] 0.32 0.0430 0.262 0.31 0.37
## A_ij[206,1] 0.16 0.0761 0.073 0.15 0.27
## A_ij[206,2] 0.43 0.1305 0.270 0.42 0.60
## A_ij[206,3] 0.41 0.1094 0.269 0.42 0.55
## A_ij[207,1] 0.38 0.0745 0.286 0.38 0.47
## A_ij[207,2] 0.35 0.0712 0.267 0.34 0.45
## A_ij[207,3] 0.27 0.0512 0.206 0.27 0.33
## A_ij[208,1] 0.32 0.0627 0.242 0.32 0.41
## A_ij[208,2] 0.41 0.0660 0.330 0.42 0.49
## A_ij[208,3] 0.27 0.0434 0.212 0.26 0.33
## A_ij[209,1] 0.29 0.0711 0.204 0.28 0.39
## A_ij[209,2] 0.28 0.0675 0.200 0.28 0.37
## A_ij[209,3] 0.43 0.0716 0.344 0.42 0.53
## A_ij[210,1] 0.31 0.0482 0.254 0.31 0.36
## A_ij[210,2] 0.30 0.0472 0.248 0.30 0.36
## A_ij[210,3] 0.39 0.0398 0.339 0.39 0.44
## A_ij[211,1] 0.30 0.0585 0.229 0.30 0.38
## A_ij[211,2] 0.41 0.0628 0.328 0.41 0.50
## A_ij[211,3] 0.28 0.0481 0.223 0.28 0.34
## A_ij[212,1] 0.40 0.0343 0.356 0.40 0.44
## A_ij[212,2] 0.30 0.0292 0.265 0.30 0.33
## A_ij[212,3] 0.30 0.0251 0.271 0.30 0.34
## A_ij[213,1] 0.40 0.0338 0.358 0.40 0.44
## A_ij[213,2] 0.30 0.0289 0.264 0.30 0.33
## A_ij[213,3] 0.30 0.0243 0.272 0.30 0.34
## A_ij[214,1] 0.40 0.0965 0.274 0.40 0.53
## A_ij[214,2] 0.26 0.0741 0.166 0.25 0.36
## A_ij[214,3] 0.34 0.0804 0.235 0.33 0.43
## A_ij[215,1] 0.29 0.0859 0.187 0.28 0.40
## A_ij[215,2] 0.49 0.0947 0.371 0.49 0.61
## A_ij[215,3] 0.22 0.0570 0.147 0.22 0.30
## A_ij[216,1] 0.28 0.0752 0.188 0.27 0.39
## A_ij[216,2] 0.27 0.0709 0.190 0.27 0.37
## A_ij[216,3] 0.45 0.0770 0.354 0.44 0.55
## A_ij[217,1] 0.35 0.0373 0.300 0.35 0.41
## A_ij[217,2] 0.32 0.0347 0.274 0.32 0.36
## A_ij[217,3] 0.33 0.0308 0.293 0.33 0.37
## A_ij[218,1] 0.25 0.0609 0.179 0.25 0.34
## A_ij[218,2] 0.38 0.0719 0.285 0.38 0.46
## A_ij[218,3] 0.37 0.0589 0.291 0.37 0.45
## A_ij[219,1] 0.37 0.0267 0.335 0.37 0.40
## A_ij[219,2] 0.32 0.0242 0.294 0.32 0.35
## A_ij[219,3] 0.31 0.0201 0.282 0.31 0.33
## A_ij[220,1] 0.52 0.0860 0.408 0.51 0.63
## A_ij[220,2] 0.22 0.0603 0.147 0.21 0.29
## A_ij[220,3] 0.26 0.0598 0.189 0.26 0.35
## A_ij[221,1] 0.48 0.0674 0.392 0.47 0.56
## A_ij[221,2] 0.25 0.0515 0.187 0.24 0.31
## A_ij[221,3] 0.28 0.0456 0.217 0.27 0.34
## A_ij[222,1] 0.37 0.0600 0.298 0.36 0.44
## A_ij[222,2] 0.38 0.0593 0.311 0.38 0.46
## A_ij[222,3] 0.26 0.0378 0.202 0.26 0.30
## A_ij[223,1] 0.29 0.0664 0.202 0.29 0.38
## A_ij[223,2] 0.32 0.0652 0.242 0.32 0.41
## A_ij[223,3] 0.39 0.0651 0.301 0.39 0.46
## A_ij[224,1] 0.42 0.0822 0.315 0.41 0.54
## A_ij[224,2] 0.27 0.0708 0.180 0.27 0.37
## A_ij[224,3] 0.31 0.0597 0.231 0.31 0.39
## A_ij[225,1] 0.27 0.0838 0.175 0.27 0.37
## A_ij[225,2] 0.28 0.0852 0.189 0.27 0.39
## A_ij[225,3] 0.45 0.0794 0.350 0.45 0.55
## A_ij[226,1] 0.25 0.0653 0.165 0.25 0.33
## A_ij[226,2] 0.33 0.0764 0.242 0.33 0.43
## A_ij[226,3] 0.42 0.0730 0.333 0.42 0.52
## A_ij[227,1] 0.36 0.0566 0.291 0.37 0.43
## A_ij[227,2] 0.37 0.0560 0.305 0.37 0.44
## A_ij[227,3] 0.27 0.0386 0.218 0.27 0.32
## A_ij[228,1] 0.34 0.0270 0.309 0.35 0.38
## A_ij[228,2] 0.31 0.0239 0.280 0.31 0.34
## A_ij[228,3] 0.35 0.0243 0.318 0.35 0.37
## A_ij[229,1] 0.41 0.0679 0.327 0.41 0.51
## A_ij[229,2] 0.23 0.0465 0.175 0.23 0.29
## A_ij[229,3] 0.35 0.0582 0.281 0.35 0.42
## A_ij[230,1] 0.29 0.0694 0.207 0.29 0.38
## A_ij[230,2] 0.29 0.0636 0.209 0.28 0.37
## A_ij[230,3] 0.42 0.0676 0.335 0.42 0.51
## A_ij[231,1] 0.27 0.0616 0.194 0.27 0.37
## A_ij[231,2] 0.37 0.0693 0.286 0.37 0.47
## A_ij[231,3] 0.35 0.0642 0.275 0.35 0.43
## A_ij[232,1] 0.39 0.0485 0.333 0.38 0.45
## A_ij[232,2] 0.25 0.0349 0.212 0.25 0.30
## A_ij[232,3] 0.36 0.0417 0.311 0.36 0.41
## A_ij[233,1] 0.28 0.0342 0.232 0.28 0.31
## A_ij[233,2] 0.37 0.0381 0.318 0.36 0.42
## A_ij[233,3] 0.36 0.0334 0.316 0.36 0.40
## A_ij[234,1] 0.39 0.0884 0.284 0.39 0.50
## A_ij[234,2] 0.34 0.0859 0.232 0.33 0.45
## A_ij[234,3] 0.27 0.0561 0.204 0.27 0.35
## A_ij[235,1] 0.29 0.0538 0.220 0.29 0.36
## A_ij[235,2] 0.31 0.0525 0.245 0.31 0.37
## A_ij[235,3] 0.40 0.0525 0.336 0.40 0.47
## A_ij[236,1] 0.29 0.0695 0.208 0.28 0.38
## A_ij[236,2] 0.36 0.0738 0.264 0.36 0.46
## A_ij[236,3] 0.35 0.0657 0.269 0.35 0.44
## A_ij[237,1] 0.26 0.0466 0.199 0.26 0.32
## A_ij[237,2] 0.45 0.0527 0.380 0.45 0.51
## A_ij[237,3] 0.29 0.0418 0.234 0.29 0.34
## A_ij[238,1] 0.24 0.0569 0.166 0.24 0.32
## A_ij[238,2] 0.48 0.0699 0.386 0.49 0.57
## A_ij[238,3] 0.28 0.0549 0.203 0.27 0.35
## A_ij[239,1] 0.40 0.1012 0.274 0.39 0.54
## A_ij[239,2] 0.39 0.0989 0.276 0.38 0.53
## A_ij[239,3] 0.22 0.0572 0.143 0.21 0.29
## A_ij[240,1] 0.41 0.0475 0.347 0.40 0.47
## A_ij[240,2] 0.28 0.0416 0.232 0.27 0.33
## A_ij[240,3] 0.32 0.0341 0.267 0.32 0.36
## A_ij[241,1] 0.27 0.0735 0.180 0.26 0.37
## A_ij[241,2] 0.42 0.0884 0.297 0.43 0.53
## A_ij[241,3] 0.31 0.0658 0.225 0.30 0.40
## A_ij[242,1] 0.26 0.0744 0.162 0.25 0.35
## A_ij[242,2] 0.39 0.0918 0.264 0.38 0.53
## A_ij[242,3] 0.35 0.0761 0.261 0.35 0.45
## A_ij[243,1] 0.32 0.0367 0.273 0.32 0.36
## A_ij[243,2] 0.38 0.0394 0.332 0.38 0.43
## A_ij[243,3] 0.30 0.0298 0.264 0.30 0.34
## A_ij[244,1] 0.42 0.0642 0.341 0.42 0.50
## A_ij[244,2] 0.24 0.0474 0.180 0.23 0.30
## A_ij[244,3] 0.34 0.0535 0.272 0.35 0.41
## A_ij[245,1] 0.23 0.0550 0.162 0.22 0.30
## A_ij[245,2] 0.36 0.0716 0.275 0.36 0.46
## A_ij[245,3] 0.41 0.0639 0.327 0.41 0.49
## A_ij[246,1] 0.44 0.0656 0.360 0.44 0.52
## A_ij[246,2] 0.27 0.0521 0.207 0.27 0.34
## A_ij[246,3] 0.29 0.0471 0.230 0.28 0.35
## A_ij[247,1] 0.41 0.0608 0.337 0.41 0.49
## A_ij[247,2] 0.33 0.0552 0.259 0.33 0.40
## A_ij[247,3] 0.26 0.0375 0.217 0.26 0.31
## A_ij[248,1] 0.24 0.0569 0.161 0.23 0.30
## A_ij[248,2] 0.33 0.0682 0.238 0.33 0.42
## A_ij[248,3] 0.43 0.0597 0.358 0.43 0.51
## A_ij[249,1] 0.17 0.0648 0.091 0.16 0.26
## A_ij[249,2] 0.48 0.1086 0.343 0.48 0.62
## A_ij[249,3] 0.35 0.0877 0.241 0.35 0.47
## A_ij[250,1] 0.27 0.0601 0.206 0.27 0.35
## A_ij[250,2] 0.42 0.0684 0.335 0.43 0.52
## A_ij[250,3] 0.30 0.0522 0.246 0.29 0.38
## A_ij[251,1] 0.42 0.0581 0.348 0.42 0.50
## A_ij[251,2] 0.27 0.0447 0.216 0.26 0.32
## A_ij[251,3] 0.31 0.0460 0.254 0.31 0.37
## A_ij[252,1] 0.40 0.1071 0.266 0.40 0.55
## A_ij[252,2] 0.27 0.0839 0.166 0.26 0.38
## A_ij[252,3] 0.33 0.0913 0.217 0.33 0.45
## A_ij[253,1] 0.27 0.0457 0.212 0.27 0.33
## A_ij[253,2] 0.42 0.0510 0.356 0.42 0.48
## A_ij[253,3] 0.31 0.0435 0.253 0.31 0.36
## A_ij[254,1] 0.27 0.0736 0.187 0.27 0.35
## A_ij[254,2] 0.29 0.0752 0.198 0.28 0.38
## A_ij[254,3] 0.44 0.0693 0.355 0.44 0.53
## A_ij[255,1] 0.49 0.0838 0.391 0.49 0.59
## A_ij[255,2] 0.22 0.0584 0.156 0.22 0.30
## A_ij[255,3] 0.28 0.0620 0.215 0.28 0.37
## A_ij[256,1] 0.48 0.0821 0.377 0.48 0.59
## A_ij[256,2] 0.26 0.0678 0.181 0.25 0.35
## A_ij[256,3] 0.26 0.0498 0.196 0.26 0.32
## A_ij[257,1] 0.35 0.0460 0.285 0.35 0.41
## A_ij[257,2] 0.33 0.0454 0.277 0.34 0.39
## A_ij[257,3] 0.32 0.0362 0.276 0.32 0.37
## A_ij[258,1] 0.41 0.0753 0.320 0.41 0.51
## A_ij[258,2] 0.24 0.0549 0.174 0.23 0.31
## A_ij[258,3] 0.35 0.0611 0.273 0.36 0.43
## A_ij[259,1] 0.39 0.1248 0.229 0.38 0.57
## A_ij[259,2] 0.23 0.1019 0.128 0.21 0.38
## A_ij[259,3] 0.38 0.1081 0.240 0.38 0.51
## A_ij[260,1] 0.23 0.0525 0.158 0.23 0.29
## A_ij[260,2] 0.37 0.0665 0.284 0.37 0.45
## A_ij[260,3] 0.40 0.0574 0.326 0.41 0.48
## A_ij[261,1] 0.32 0.0717 0.225 0.32 0.40
## A_ij[261,2] 0.41 0.0766 0.308 0.41 0.51
## A_ij[261,3] 0.28 0.0506 0.217 0.27 0.35
## A_ij[262,1] 0.32 0.0812 0.215 0.31 0.43
## A_ij[262,2] 0.44 0.0843 0.335 0.44 0.55
## A_ij[262,3] 0.23 0.0516 0.162 0.23 0.30
## A_ij[263,1] 0.36 0.0704 0.266 0.36 0.44
## A_ij[263,2] 0.36 0.0714 0.268 0.36 0.45
## A_ij[263,3] 0.28 0.0459 0.226 0.27 0.35
## A_ij[264,1] 0.33 0.0736 0.235 0.33 0.43
## A_ij[264,2] 0.39 0.0757 0.303 0.39 0.50
## A_ij[264,3] 0.28 0.0570 0.207 0.27 0.34
## A_ij[265,1] 0.37 0.0520 0.307 0.37 0.45
## A_ij[265,2] 0.28 0.0465 0.228 0.28 0.35
## A_ij[265,3] 0.34 0.0424 0.289 0.35 0.40
## A_ij[266,1] 0.35 0.0989 0.219 0.35 0.48
## A_ij[266,2] 0.39 0.1027 0.270 0.38 0.52
## A_ij[266,3] 0.26 0.0702 0.176 0.25 0.36
## A_ij[267,1] 0.37 0.0632 0.290 0.37 0.45
## A_ij[267,2] 0.30 0.0540 0.234 0.29 0.37
## A_ij[267,3] 0.33 0.0558 0.263 0.33 0.41
## A_ij[268,1] 0.27 0.0464 0.217 0.27 0.34
## A_ij[268,2] 0.42 0.0552 0.354 0.42 0.50
## A_ij[268,3] 0.30 0.0418 0.251 0.30 0.36
## A_ij[269,1] 0.41 0.0804 0.303 0.42 0.51
## A_ij[269,2] 0.27 0.0653 0.187 0.26 0.36
## A_ij[269,3] 0.32 0.0640 0.239 0.32 0.40
## A_ij[270,1] 0.46 0.0950 0.341 0.45 0.58
## A_ij[270,2] 0.19 0.0559 0.126 0.18 0.26
## A_ij[270,3] 0.35 0.0801 0.253 0.35 0.46
## A_ij[271,1] 0.21 0.0529 0.145 0.21 0.28
## A_ij[271,2] 0.42 0.0742 0.329 0.42 0.51
## A_ij[271,3] 0.37 0.0591 0.294 0.37 0.45
## A_ij[272,1] 0.33 0.0383 0.288 0.33 0.38
## A_ij[272,2] 0.38 0.0392 0.331 0.37 0.42
## A_ij[272,3] 0.29 0.0292 0.254 0.29 0.33
## A_ij[273,1] 0.26 0.0516 0.193 0.25 0.32
## A_ij[273,2] 0.36 0.0600 0.283 0.36 0.43
## A_ij[273,3] 0.38 0.0489 0.313 0.38 0.45
## A_ij[274,1] 0.30 0.0493 0.239 0.30 0.36
## A_ij[274,2] 0.31 0.0507 0.255 0.31 0.38
## A_ij[274,3] 0.39 0.0413 0.340 0.39 0.44
## A_ij[275,1] 0.41 0.0499 0.346 0.41 0.47
## A_ij[275,2] 0.26 0.0376 0.218 0.26 0.31
## A_ij[275,3] 0.33 0.0400 0.280 0.33 0.38
## A_ij[276,1] 0.32 0.0652 0.233 0.32 0.41
## A_ij[276,2] 0.32 0.0668 0.249 0.32 0.41
## A_ij[276,3] 0.35 0.0538 0.285 0.35 0.42
## A_ij[277,1] 0.26 0.0674 0.174 0.25 0.35
## A_ij[277,2] 0.39 0.0774 0.300 0.39 0.49
## A_ij[277,3] 0.34 0.0694 0.253 0.34 0.43
## A_ij[278,1] 0.36 0.0769 0.257 0.35 0.46
## A_ij[278,2] 0.34 0.0714 0.252 0.34 0.44
## A_ij[278,3] 0.30 0.0636 0.223 0.29 0.38
## A_ij[279,1] 0.21 0.0497 0.152 0.21 0.28
## A_ij[279,2] 0.44 0.0701 0.345 0.44 0.52
## A_ij[279,3] 0.35 0.0577 0.281 0.35 0.43
## A_ij[280,1] 0.37 0.0528 0.299 0.37 0.44
## A_ij[280,2] 0.29 0.0443 0.240 0.29 0.35
## A_ij[280,3] 0.34 0.0462 0.282 0.34 0.40
## A_ij[281,1] 0.35 0.0403 0.303 0.35 0.41
## A_ij[281,2] 0.34 0.0396 0.292 0.34 0.39
## A_ij[281,3] 0.30 0.0316 0.267 0.30 0.34
## A_ij[282,1] 0.28 0.0380 0.236 0.28 0.33
## A_ij[282,2] 0.38 0.0431 0.319 0.38 0.43
## A_ij[282,3] 0.34 0.0340 0.296 0.34 0.39
## A_ij[283,1] 0.48 0.1113 0.337 0.47 0.63
## A_ij[283,2] 0.27 0.0900 0.157 0.27 0.38
## A_ij[283,3] 0.25 0.0765 0.157 0.24 0.35
## A_ij[284,1] 0.28 0.0591 0.204 0.27 0.36
## A_ij[284,2] 0.36 0.0643 0.279 0.36 0.45
## A_ij[284,3] 0.36 0.0585 0.282 0.35 0.43
## A_ij[285,1] 0.33 0.0550 0.257 0.33 0.40
## A_ij[285,2] 0.36 0.0566 0.289 0.36 0.43
## A_ij[285,3] 0.31 0.0425 0.258 0.31 0.37
## A_ij[286,1] 0.42 0.0524 0.355 0.42 0.49
## A_ij[286,2] 0.25 0.0377 0.205 0.25 0.30
## A_ij[286,3] 0.33 0.0428 0.278 0.33 0.39
## A_ij[287,1] 0.17 0.0616 0.093 0.16 0.24
## A_ij[287,2] 0.44 0.1020 0.311 0.43 0.57
## A_ij[287,3] 0.40 0.0898 0.275 0.40 0.51
## A_ij[288,1] 0.47 0.0746 0.375 0.47 0.57
## A_ij[288,2] 0.24 0.0584 0.170 0.24 0.32
## A_ij[288,3] 0.29 0.0511 0.225 0.29 0.35
## A_ij[289,1] 0.37 0.0218 0.342 0.37 0.40
## A_ij[289,2] 0.29 0.0181 0.270 0.29 0.32
## A_ij[289,3] 0.34 0.0187 0.313 0.34 0.36
## A_ij[290,1] 0.42 0.0760 0.324 0.42 0.52
## A_ij[290,2] 0.30 0.0656 0.224 0.30 0.39
## A_ij[290,3] 0.28 0.0529 0.210 0.28 0.34
## A_ij[291,1] 0.36 0.0456 0.301 0.35 0.42
## A_ij[291,2] 0.37 0.0452 0.310 0.37 0.42
## A_ij[291,3] 0.28 0.0317 0.233 0.28 0.32
## A_ij[292,1] 0.27 0.0561 0.198 0.27 0.33
## A_ij[292,2] 0.34 0.0614 0.257 0.33 0.41
## A_ij[292,3] 0.40 0.0512 0.332 0.40 0.46
## A_ij[293,1] 0.29 0.0315 0.254 0.29 0.34
## A_ij[293,2] 0.34 0.0324 0.301 0.34 0.38
## A_ij[293,3] 0.36 0.0295 0.324 0.36 0.40
## A_ij[294,1] 0.44 0.0639 0.362 0.44 0.53
## A_ij[294,2] 0.23 0.0429 0.177 0.23 0.28
## A_ij[294,3] 0.33 0.0518 0.264 0.33 0.40
## A_ij[295,1] 0.35 0.0536 0.278 0.35 0.42
## A_ij[295,2] 0.30 0.0481 0.245 0.29 0.36
## A_ij[295,3] 0.35 0.0487 0.294 0.35 0.42
## A_ij[296,1] 0.35 0.0709 0.256 0.35 0.45
## A_ij[296,2] 0.29 0.0615 0.217 0.29 0.38
## A_ij[296,3] 0.36 0.0645 0.283 0.35 0.44
## A_ij[297,1] 0.32 0.0177 0.299 0.32 0.34
## A_ij[297,2] 0.36 0.0183 0.335 0.36 0.38
## A_ij[297,3] 0.32 0.0149 0.302 0.32 0.34
## A_ij[298,1] 0.48 0.0874 0.368 0.48 0.60
## A_ij[298,2] 0.22 0.0598 0.140 0.21 0.30
## A_ij[298,3] 0.30 0.0677 0.223 0.30 0.39
## A_ij[299,1] 0.45 0.0595 0.378 0.44 0.53
## A_ij[299,2] 0.23 0.0423 0.182 0.23 0.29
## A_ij[299,3] 0.32 0.0463 0.257 0.31 0.37
## A_ij[300,1] 0.21 0.0581 0.140 0.21 0.28
## A_ij[300,2] 0.37 0.0763 0.275 0.37 0.47
## A_ij[300,3] 0.41 0.0655 0.325 0.42 0.50</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="st">&quot;Estimated regressors of hidden states&quot;</span>)</code></pre></div>
<pre><code>## [1] &quot;Estimated regressors of hidden states&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(stan.fit,
        <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">'w_km'</span>),
        <span class="dt">probs =</span> <span class="kw">c</span>(<span class="fl">0.10</span>, <span class="fl">0.50</span>, <span class="fl">0.90</span>))$summary[, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>)]</code></pre></div>
<pre><code>##             mean  sd  10%     50% 90%
## w_km[1,1]  0.171 3.0 -3.8  0.6202 3.8
## w_km[1,2]  0.201 2.9 -3.6  0.0105 3.9
## w_km[1,3]  0.065 2.8 -3.2  0.0045 3.5
## w_km[1,4]  0.745 3.0 -2.7  0.6329 4.8
## w_km[2,1]  0.301 3.0 -3.9  0.8565 3.9
## w_km[2,2]  0.390 2.9 -3.4  0.2341 4.1
## w_km[2,3] -0.012 2.8 -3.4 -0.1574 3.4
## w_km[2,4]  0.395 3.0 -3.0  0.2001 4.6
## w_km[3,1]  0.117 3.0 -4.1  0.5581 3.7
## w_km[3,2]  0.259 2.9 -3.5  0.0983 4.0
## w_km[3,3] -0.162 2.8 -3.5 -0.2350 3.2
## w_km[3,4]  0.534 2.9 -2.9  0.3449 4.7</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="st">&quot;Estimated regressors and standard deviation of observations in each state&quot;</span>)</code></pre></div>
<pre><code>## [1] &quot;Estimated regressors and standard deviation of observations in each state&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(stan.fit,
        <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">'b_km'</span>, <span class="st">'s_k'</span>),
        <span class="dt">probs =</span> <span class="kw">c</span>(<span class="fl">0.10</span>, <span class="fl">0.50</span>, <span class="fl">0.90</span>))$summary[, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>)]</code></pre></div>
<pre><code>##             mean    sd    10%    50%   90%
## b_km[1,1] -0.101 0.341 -0.544 -0.098  0.34
## b_km[1,2] -1.067 0.281 -1.440 -1.068 -0.70
## b_km[1,3] -4.884 0.329 -5.302 -4.894 -4.46
## b_km[1,4] -0.083 0.320 -0.511 -0.078  0.29
## b_km[2,1]  0.845 0.128  0.688  0.850  1.02
## b_km[2,2]  5.002 0.091  4.890  4.999  5.12
## b_km[2,3]  0.052 0.100 -0.076  0.063  0.17
## b_km[2,4] -0.261 0.111 -0.395 -0.271 -0.11
## b_km[3,1]  5.049 0.035  5.001  5.049  5.09
## b_km[3,2]  6.012 0.026  5.977  6.015  6.04
## b_km[3,3]  6.992 0.022  6.963  6.990  7.02
## b_km[3,4]  0.456 0.034  0.412  0.456  0.50
## s_k[1]     2.741 0.211  2.491  2.732  3.00
## s_k[2]     1.025 0.097  0.905  1.016  1.16
## s_k[3]     0.260 0.021  0.233  0.258  0.29</code></pre>
<p>We confirm that the samples drawn from the posterior density are reasonable close to the true values.</p>
<hr />
</div>
</div>
<div id="stock-market-forecasting-using-hidden-markov-model" class="section level1">
<h1>Stock Market Forecasting Using Hidden Markov Model</h1>
<p>(the replication with actual data)</p>
<hr />
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-baum1967inequality">
<p>Baum, Leonard E., and J. A. Eagon. 1967. “An Inequality with Applications to Statistical Estimation for Probabilistic Functions of Markov Processes and to a Model for Ecology.” <em>Bulletin of the American Mathematical Society</em> 73 (3). American Mathematical Society (AMS): 360–64. doi:<a href="https://doi.org/10.1090/s0002-9904-1967-11751-8">10.1090/s0002-9904-1967-11751-8</a>.</p>
</div>
<div id="ref-baum1970maximization">
<p>Baum, Leonard E., Ted Petrie, George Soules, and Norman Weiss. 1970. “A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains.” <em>The Annals of Mathematical Statistics</em> 41 (1). Institute of Mathematical Statistics: 164–71. doi:<a href="https://doi.org/10.1214/aoms/1177697196">10.1214/aoms/1177697196</a>.</p>
</div>
<div id="ref-bengio1995input">
<p>Bengio, Yoshua, and Paolo Frasconi. 1995. “An Input Output Hmm Architecture.”</p>
</div>
<div id="ref-betancourt2017identifying">
<p>Betancourt, Michael. 2017. “Identifying Bayesian Mixture Models.” <em>Stan Case Studies</em>, no. Volume 4. <a href="http://mc-stan.org/users/documentation/case-studies/identifying_mixture_models.html" class="uri">http://mc-stan.org/users/documentation/case-studies/identifying_mixture_models.html</a>.</p>
</div>
<div id="ref-carpenter2016stan">
<p>Carpenter, Bob, Andrew Gelman, Matt Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Michael A Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell. 2016. “Stan: A Probabilistic Programming Language.” <em>Journal of Statistical Software</em> 20.</p>
</div>
<div id="ref-hassan2005stock">
<p>Hassan, Md Rafiul, and Baikunth Nath. 2005. “Stock Market Forecasting Using Hidden Markov Model: A New Approach.” In <em>Intelligent Systems Design and Applications, 2005. Isda’05. Proceedings. 5th International Conference on</em>, 192–96. IEEE.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Enlarge why<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>The Stan code is treated as given by now and will be explained below<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>cite<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>cite<a href="#fnref4">↩</a></p></li>
</ol>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
